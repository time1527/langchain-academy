{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## èƒŒæ™¯\n",
    "\n",
    "åœ¨ LangChainï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©å¤§å®¶æ›´å®¹æ˜“åœ°æ„å»º LLM åº”ç”¨ç¨‹åºã€‚å…¶ä¸­ä¸€ç§å¯ä»¥æ„å»ºçš„ LLM åº”ç”¨å°±æ˜¯æ™ºèƒ½ä½“ï¼ˆagentï¼‰ã€‚å¤§å®¶å¯¹æ„å»ºæ™ºèƒ½ä½“éå¸¸å…´å¥‹ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥è‡ªåŠ¨åŒ–è®¸å¤šä»¥å‰æ— æ³•å®Œæˆçš„ä»»åŠ¡ã€‚  \n",
    "\n",
    "ä¸è¿‡åœ¨å®è·µä¸­ï¼Œæ„å»ºèƒ½å¤Ÿå¯é æ‰§è¡Œè¿™äº›ä»»åŠ¡çš„ç³»ç»Ÿéå¸¸å›°éš¾ã€‚éšç€æˆ‘ä»¬å¸®åŠ©ç”¨æˆ·å°†æ™ºèƒ½ä½“æŠ•å…¥ç”Ÿäº§ï¼Œæˆ‘ä»¬å‘ç°å¾€å¾€éœ€è¦æ›´å¤šçš„æ§åˆ¶ã€‚æ¯”å¦‚ï¼Œä½ å¯èƒ½éœ€è¦æ™ºèƒ½ä½“åœ¨ä¸€å¼€å§‹æ€»æ˜¯è°ƒç”¨æŸä¸ªç‰¹å®šå·¥å…·ï¼Œæˆ–è€…æ ¹æ®ä¸åŒçš„çŠ¶æ€ä½¿ç”¨ä¸åŒçš„æç¤ºè¯ã€‚  \n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº† [LangGraph](https://langchain-ai.github.io/langgraph/) â€”â€” ä¸€ä¸ªç”¨äºæ„å»ºå•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒç‹¬ç«‹äº LangChain åŒ…ï¼Œæ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯å¸®åŠ©å¼€å‘è€…åœ¨æ™ºèƒ½ä½“å·¥ä½œæµä¸­å®ç°æ›´å¥½çš„ç²¾ç¡®æ€§ä¸æ§åˆ¶ï¼Œä»è€Œé€‚åº”ç°å®ä¸–ç•Œç³»ç»Ÿçš„å¤æ‚æ€§ã€‚\n",
    "\n",
    "## è¯¾ç¨‹ç»“æ„\n",
    "\n",
    "æœ¬è¯¾ç¨‹ç”±ä¸€ç³»åˆ—æ¨¡å—ç»„æˆï¼Œæ¯ä¸ªæ¨¡å—éƒ½ä¸“æ³¨äº LangGraph ç›¸å…³çš„ç‰¹å®šä¸»é¢˜ã€‚ä½ ä¼šçœ‹åˆ°æ¯ä¸ªæ¨¡å—å¯¹åº”ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å¤¹ä¸­åŒ…å«ä¸€ç³»åˆ— notebookã€‚æ¯ä¸ª notebook éƒ½ä¼šé…æœ‰è®²è§£è§†é¢‘ï¼Œä½† notebook æœ¬èº«ä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œå› ä¸ºå®ƒä»¬åŒ…å«å®Œæ•´çš„è§£é‡Šï¼Œå¯ä»¥ä¸ä¾èµ–è§†é¢‘å•ç‹¬é˜…è¯»ã€‚  \n",
    "\n",
    "æ¯ä¸ªæ¨¡å—æ–‡ä»¶å¤¹ä¸­è¿˜åŒ…å«ä¸€ä¸ª `studio` æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«ä¸€ç»„å¯ä»¥åŠ è½½åˆ° [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio) çš„å›¾è¡¨ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸“é—¨ä¸ºæ„å»º LangGraph åº”ç”¨å¼€å‘çš„ IDEã€‚\n",
    "\n",
    "## ç¯å¢ƒé…ç½®\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·æŒ‰ç…§ `README` æ–‡ä»¶ä¸­çš„è¯´æ˜æ¥åˆ›å»ºç¯å¢ƒå¹¶å®‰è£…ä¾èµ–ã€‚\n",
    "\n",
    "## èŠå¤©æ¨¡å‹\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ [èŠå¤©æ¨¡å‹](https://python.langchain.com/v0.2/docs/concepts/#chat-models)ã€‚èŠå¤©æ¨¡å‹çš„ä½œç”¨æ˜¯ï¼šæ¥æ”¶ä¸€ç³»åˆ—æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å‡ºã€‚LangChain æœ¬èº«ä¸æ‰˜ç®¡ä»»ä½•èŠå¤©æ¨¡å‹ï¼Œè€Œæ˜¯ä¾èµ–ç¬¬ä¸‰æ–¹çš„é›†æˆã€‚[è¿™é‡Œ](https://python.langchain.com/v0.2/docs/integrations/chat/) åˆ—å‡ºäº† LangChain ä¸­æ”¯æŒçš„ç¬¬ä¸‰æ–¹èŠå¤©æ¨¡å‹é›†æˆï¼  \n",
    "\n",
    "é»˜è®¤æƒ…å†µä¸‹ï¼Œæœ¬è¯¾ç¨‹ä¼šä½¿ç”¨ [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/)ï¼Œå› ä¸ºå®ƒæ—¢æµè¡Œåˆé«˜æ•ˆã€‚è¯·æ³¨æ„ï¼Œä½ éœ€è¦ç¡®ä¿å·²ç»è®¾ç½®äº† `OPENAI_API_KEY`ã€‚  \n",
    "\n",
    "è®©æˆ‘ä»¬å…ˆæ£€æŸ¥ä¸€ä¸‹æ˜¯å¦å·²ç»è®¾ç½®äº† `OPENAI_API_KEY`ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œå°†ä¼šæç¤ºä½ è¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langchain_community tavily-python dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "dashscope_chat = ChatTongyi(model=\"qwen-plus\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "LangChain ä¸­çš„èŠå¤©æ¨¡å‹æœ‰ä¸€äº›[é»˜è®¤æ–¹æ³•](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface)ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š\n",
    "\n",
    "* `stream`: æµå¼è¿”å›å“åº”çš„ç‰‡æ®µ  \n",
    "* `invoke`: åœ¨è¾“å…¥ä¸Šè°ƒç”¨é“¾  \n",
    "\n",
    "å¦å¤–ï¼Œå¦‚å‰é¢æåˆ°çš„ï¼ŒèŠå¤©æ¨¡å‹ä¼šæ¥æ”¶[æ¶ˆæ¯](https://python.langchain.com/v0.2/docs/concepts/#messages)ä½œä¸ºè¾“å…¥ã€‚æ¶ˆæ¯åŒ…å«ä¸€ä¸ªè§’è‰²ï¼ˆæè¿°æ˜¯è°åœ¨è¯´è¯ï¼‰å’Œä¸€ä¸ªå†…å®¹å±æ€§ã€‚åé¢æˆ‘ä»¬ä¼šæ›´æ·±å…¥åœ°è®¨è®ºè¿™ä¸€ç‚¹ï¼Œè¿™é‡Œå…ˆå±•ç¤ºåŸºç¡€ç”¨æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? ğŸ˜Š', additional_kwargs={}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': '3b663b89-e87c-4eb1-b17b-3a334483a1e6', 'token_usage': {'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--1b442c35-6129-4a34-aec1-bce835a7278c-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages\n",
    "dashscope_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª `AIMessage` å“åº”ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥ç”¨å­—ç¬¦ä¸²æ¥è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚å½“è¾“å…¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œå®ƒä¼šè¢«è½¬æ¢æˆä¸€ä¸ª `HumanMessage`ï¼Œç„¶åä¼ é€’ç»™åº•å±‚æ¨¡å‹ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? ğŸ˜Š', additional_kwargs={}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': 'ddd38dba-24da-4815-9e2a-b2d6d33ad968', 'token_usage': {'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--706d7233-612a-4a17-8525-8e5c918e722d-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashscope_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542b8705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseChatModel.stream at 0x10d03c740>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashscope_chat.stream(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "è¯¥æ¥å£åœ¨æ‰€æœ‰èŠå¤©æ¨¡å‹ä¸­éƒ½æ˜¯ä¸€è‡´çš„ï¼Œå¹¶ä¸”æ¨¡å‹é€šå¸¸ä¼šåœ¨æ¯ä¸ª notebook å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡ã€‚  \n",
    "\n",
    "å› æ­¤ï¼Œå¦‚æœä½ æ›´åå¥½å…¶ä»–æä¾›å•†ï¼Œå¯ä»¥è½»æ¾åˆ‡æ¢æ¨¡å‹ï¼Œè€Œæ— éœ€æ›´æ”¹ä¸‹æ¸¸ä»£ç ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## æœç´¢å·¥å…·\n",
    "\n",
    "ä½ è¿˜ä¼šåœ¨ README ä¸­çœ‹åˆ° [Tavily](https://tavily.com/)ï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸º LLM å’Œ RAG ä¼˜åŒ–çš„æœç´¢å¼•æ“ï¼Œæ—¨åœ¨æä¾›é«˜æ•ˆã€å¿«é€Ÿä¸”æŒä¹…çš„æœç´¢ç»“æœã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œå®ƒæ³¨å†Œéå¸¸ç®€å•ï¼Œå¹¶ä¸”æä¾›äº†æ…·æ…¨çš„å…è´¹å¥—é¤ã€‚  \n",
    "\n",
    "åœ¨æŸäº›è¯¾ç¨‹ï¼ˆæ¨¡å— 4ï¼‰ä¸­ä¼šé»˜è®¤ä½¿ç”¨ Tavilyï¼Œä¸è¿‡å½“ç„¶ï¼Œå¦‚æœä½ æƒ³ä¿®æ”¹ä»£ç ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–æœç´¢å·¥å…·ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/zsgg61wn27zbcvccfss34hpw0000gq/T/ipykernel_41556/1344879509.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of whatâ€™s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) â€“ based AI agents.\\n It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents.',\n",
       "  'score': 0.947386},\n",
       " {'title': 'Overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/python/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents - including Klarna, Replit, Elastic, and more - LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.',\n",
       "  'score': 0.9471519},\n",
       " {'title': 'What is LangGraph? - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraphâ€™s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.',\n",
       "  'score': 0.94608605}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
