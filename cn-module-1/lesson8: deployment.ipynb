{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e83a41b",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/deployment.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239303-lesson-8-deployment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20242c4-0010-4065-89f6-0e0b16c7da6e",
   "metadata": {},
   "source": [
    "# éƒ¨ç½²ï¼ˆDeploymentï¼‰\n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬å·²ç»æ„å»ºäº†ä¸€ä¸ªå¸¦è®°å¿†çš„æ™ºèƒ½ä½“ï¼š\n",
    "\n",
    "* `act` â€”â€” è®©æ¨¡å‹è°ƒç”¨ç‰¹å®šå·¥å…·\n",
    "* `observe` â€”â€” å°†å·¥å…·è¾“å‡ºä¼ å›ç»™æ¨¡å‹\n",
    "* `reason` â€”â€” è®©æ¨¡å‹åŸºäºå·¥å…·è¾“å‡ºè¿›è¡Œæ¨ç†ï¼Œä»¥å†³å®šä¸‹ä¸€æ­¥ï¼ˆè°ƒç”¨å·¥å…·æˆ–ç›´æ¥å›å¤ï¼‰\n",
    "* `persist state` â€”â€” ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹å™¨ï¼Œæ”¯æŒå¸¦ä¸­æ–­çš„é•¿å¯¹è¯\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•æŠŠæ™ºèƒ½ä½“å®é™…éƒ¨ç½²åˆ°æœ¬åœ°çš„ Studioï¼Œä»¥åŠéƒ¨ç½²åˆ° `LangGraph Cloud`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f348498b-f277-4514-b163-fe5ed9afe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph_sdk langchain_core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d0f4a7-82ee-4458-bd9a-e246ce2dc4ae",
   "metadata": {},
   "source": [
    "## æ¦‚å¿µ\n",
    "\n",
    "éœ€è¦ç†è§£çš„å‡ ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "\n",
    "`LangGraph` â€”â€”\n",
    "- Python ä¸ JavaScript åº“\n",
    "- ç”¨äºåˆ›å»ºæ™ºèƒ½ä½“å·¥ä½œæµ\n",
    "\n",
    "`LangGraph API` â€”â€”\n",
    "- æ‰“åŒ…å›¾ä»£ç \n",
    "- æä¾›ä»»åŠ¡é˜Ÿåˆ—ä»¥ç®¡ç†å¼‚æ­¥æ“ä½œ\n",
    "- ä¸ºè·¨äº¤äº’ç»´æŒçŠ¶æ€æä¾›æŒä¹…åŒ–èƒ½åŠ›\n",
    "\n",
    "`LangGraph Cloud` â€”â€”\n",
    "- LangGraph API çš„æ‰˜ç®¡æœåŠ¡\n",
    "- æ”¯æŒä» GitHub ä»“åº“éƒ¨ç½²å›¾\n",
    "- æä¾›å·²éƒ¨ç½²å›¾çš„ç›‘æ§ä¸è¿½è¸ª\n",
    "- æ¯ä¸ªéƒ¨ç½²éƒ½æœ‰å”¯ä¸€ URL å¯è®¿é—®\n",
    "\n",
    "`LangGraph Studio` â€”â€”\n",
    "- LangGraph åº”ç”¨çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰\n",
    "- ä»¥ API ä¸ºåç«¯ï¼Œæ”¯æŒåœ¨ç•Œé¢ä¸­å®æ—¶æµ‹è¯•ä¸æ¢ç´¢å›¾\n",
    "- å¯æœ¬åœ°è¿è¡Œæˆ–é…åˆäº‘éƒ¨ç½²\n",
    "\n",
    "`LangGraph SDK` â€”â€”\n",
    "- ç”¨äºä»¥ç¼–ç¨‹æ–¹å¼ä¸ LangGraph å›¾äº¤äº’çš„ Python åº“\n",
    "- æ— è®ºæœ¬åœ°è¿˜æ˜¯äº‘ç«¯ï¼Œéƒ½æä¾›ä¸€è‡´çš„æ“ä½œæ¥å£\n",
    "- æ”¯æŒåˆ›å»ºå®¢æˆ·ç«¯ã€è®¿é—®åŠ©ç†ã€ç®¡ç†çº¿ç¨‹ã€æ‰§è¡Œè¿è¡Œç­‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa75ebd4-91fe-42c5-8122-c81e72133477",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    raise Exception(\n",
    "        \"Unfortunately LangGraph Studio is currently not supported on Google Colab\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b281d8-bd07-4721-922c-347838ceee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c96f353-5dc3-41c8-a3e4-6bf07ca455f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1352fa-68ad-4963-890e-c95d93570917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {},\n",
       " 'context': {},\n",
       " 'metadata': {'created_by': 'system'},\n",
       " 'name': 'agent',\n",
       " 'created_at': '2025-09-19T16:00:03.733457+00:00',\n",
       " 'updated_at': '2025-09-19T16:00:03.733457+00:00',\n",
       " 'version': 1,\n",
       " 'description': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9c28a0-d712-496c-b191-7d620589ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4177-3644-43fa-a2f1-08f73292d1a6",
   "metadata": {},
   "source": [
    "## æœ¬åœ°æµ‹è¯•\n",
    "\n",
    "**âš ï¸ è¯´æ˜**\n",
    "\n",
    "è‡ªè¿™äº›è§†é¢‘å½•åˆ¶ä»¥æ¥ï¼Œæˆ‘ä»¬å·²æ›´æ–°äº† Studioï¼Œä½¿å…¶å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ã€‚ç°åœ¨æ¨èä»¥è¿™ç§æ–¹å¼è¿è¡Œ Studioï¼ˆè€Œä¸æ˜¯è§†é¢‘ä¸­å±•ç¤ºçš„æ¡Œé¢åº”ç”¨ï¼‰ã€‚æœ‰å…³æœ¬åœ°å¼€å‘æœåŠ¡å™¨çš„æ–‡æ¡£è§[è¿™é‡Œ](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server)ï¼Œå¦‚ä½•è¿è¡Œæœ¬åœ° Studio è§[è¿™é‡Œ](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)ã€‚è¦å¯åŠ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨ï¼Œè¯·åœ¨æœ¬æ¨¡å—çš„ `/studio` ç›®å½•ä¸‹è¿è¡Œï¼š\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "ä½ åº”è¯¥èƒ½çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š\n",
    "```\n",
    "- ğŸš€ API: http://127.0.0.1:2024\n",
    "- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ğŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ Studio UIï¼š`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f65a4480-66b3-48bf-9158-191a7b8c1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8ff20328-5fea-4fb9-b70f-b3bce5f76a9a', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_4f73c642988443f4939c49', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 3, \"b\": 2}'}}]}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '66a2333b-5e0b-4ccc-a27b-bf4e377ff1b1', 'token_usage': {'input_tokens': 352, 'output_tokens': 24, 'total_tokens': 376, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--67047a11-1288-44c5-9a1a-e28af4f5dcee-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_4f73c642988443f4939c49', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '3dfef95a-9f4c-494d-918d-e97aa00059d6', 'tool_call_id': 'call_4f73c642988443f4939c49', 'artifact': None, 'status': 'success'}\n",
      "{'content': 'The result of multiplying 3 by 2 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': '53ba9622-71c3-4220-8e13-7d3a283d4be6', 'token_usage': {'input_tokens': 391, 'output_tokens': 13, 'total_tokens': 404, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--fec7f978-8af4-4c1e-93f4-2297295b96d8-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=input,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data[\"messages\"][-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa8b850-750c-4054-95e4-1c457a12ec8a",
   "metadata": {},
   "source": [
    "## äº‘ç«¯æµ‹è¯•\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥é€šè¿‡ LangSmith éƒ¨ç½²åˆ°äº‘ç«¯ï¼Œæ­¥éª¤è§[è¿™é‡Œ](https://langchain-ai.github.io/langgraph/cloud/quick_start/#deploy-from-github-with-langgraph-cloud)ã€‚\n",
    "\n",
    "### åœ¨ GitHub åˆ›å»ºæ–°ä»“åº“\n",
    "\n",
    "* æ‰“å¼€ä½ çš„ GitHub è´¦æˆ·\n",
    "* ç‚¹å‡»å³ä¸Šè§’çš„ â€œ+â€ å¹¶é€‰æ‹© `\"New repository\"`\n",
    "* ä¸ºä»“åº“å‘½åï¼ˆä¾‹å¦‚ `langchain-academy`ï¼‰\n",
    "\n",
    "### å°†ä½ çš„ GitHub ä»“åº“æ·»åŠ ä¸ºè¿œç¨‹\n",
    "\n",
    "* å›åˆ°æœ€å¼€å§‹å…‹éš† `langchain-academy` çš„æœ¬åœ°ç»ˆç«¯\n",
    "* æŠŠåˆšåˆ›å»ºçš„ GitHub ä»“åº“æ·»åŠ ä¸ºè¿œç¨‹\n",
    "\n",
    "```\n",
    "git remote add origin https://github.com/your-username/your-repo-name.git\n",
    "```\n",
    "* æ¨é€åˆ°è¿œç¨‹\n",
    "```\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "### å°† LangSmith è¿æ¥åˆ°ä½ çš„ GitHub ä»“åº“\n",
    "\n",
    "* æ‰“å¼€ [LangSmith](hhttps://smith.langchain.com/)\n",
    "* ç‚¹å‡»å·¦ä¾§çš„ `deployments` é€‰é¡¹å¡\n",
    "* é€‰æ‹© `+ New Deployment`\n",
    "* é€‰æ‹©åˆšæ‰åˆ›å»ºçš„ GitHub ä»“åº“ï¼ˆä¾‹å¦‚ `langchain-academy`ï¼‰\n",
    "* å°† `LangGraph API config file` æŒ‡å‘å…¶ä¸­ä¸€ä¸ª `studio` ç›®å½•\n",
    "* ä¾‹å¦‚ï¼Œå¯¹ module-1 ä½¿ç”¨ï¼š`module-1/studio/langgraph.json`\n",
    "* è®¾ç½®ä½ çš„ API keysï¼ˆä¾‹å¦‚ï¼Œå¯ä»¥ç›´æ¥ä» `module-1/studio/.env` æ–‡ä»¶å¤åˆ¶ï¼‰\n",
    "\n",
    "![Screenshot 2024-09-03 at 11.35.12 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fd61c93d48e5d0f47_deployment2.png)\n",
    "\n",
    "### ä¸éƒ¨ç½²äº¤äº’\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥é€šè¿‡å‡ ç§æ–¹å¼ä¸éƒ¨ç½²äº¤äº’ï¼š\n",
    "\n",
    "* ä½¿ç”¨ [SDK](https://langchain-ai.github.io/langgraph/cloud/quick_start/#use-with-the-sdk)ï¼ŒåŒä¹‹å‰ä¸€æ ·ï¼›\n",
    "* ä½¿ç”¨ [LangGraph Studio](https://langchain-ai.github.io/langgraph/cloud/quick_start/#interact-with-your-deployment-via-langgraph-studio)ã€‚\n",
    "\n",
    "![Screenshot 2024-08-23 at 10.59.36 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fa159a09a51d601de_deployment3.png)\n",
    "\n",
    "è‹¥è¦åœ¨æœ¬ç¬”è®°æœ¬ä¸­ç›´æ¥ä½¿ç”¨ SDKï¼Œè¯·ç¡®ä¿å·²è®¾ç½® `LANGSMITH_API_KEY`ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ed351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda16c-c87f-4c03-b910-d647e83400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the URL of your deployed graph\n",
    "URL = \"https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefa37c0-92fe-4e80-9d5a-80a77b1e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the agent\n",
    "agent = assistants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b810376e-f20f-443a-b1ca-d6793f358f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'created_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'updated_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d65d84-1bcf-4af4-a7c9-55e73d6c1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8ea04559-f7d4-4c82-89d9-c60fb0502f21', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-b0ea5ddd-e9ba-4242-bb8c-80eb52466c76', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1bf558e7-79ef-4f21-bb66-acafbd04677a', 'tool_call_id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'artifact': None, 'status': 'success'}\n",
      "{'content': '3 multiplied by 2 equals 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-ecc4b6ad-af15-4a85-a76c-de2ed0ed8ed9', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=input,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cb34d-c3b8-4446-a7e3-5fe938abf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
