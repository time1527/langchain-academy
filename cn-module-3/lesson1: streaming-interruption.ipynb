{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![在 Colab 中打开](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![在 LangChain Academy 中打开](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# 流式传输\n",
    "\n",
    "## 回顾\n",
    "\n",
    "在模块 2 中，我们讲了几种自定义图状态和记忆的方法。\n",
    " \n",
    "我们构建了一个带外部记忆的聊天机器人，可以维持长时间的对话。\n",
    "\n",
    "## 目标\n",
    "\n",
    "本模块将深入探讨 `human-in-the-loop`，它建立在记忆之上，让用户能够以多种方式直接与图互动。\n",
    "\n",
    "为了给 `human-in-the-loop` 奠定基础，我们先看看流式传输，这提供了多种在执行过程中可视化图输出（例如节点状态或聊天模型 token）的方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## 流式传输\n",
    "\n",
    "LangGraph 天生具备[一流的流式传输支持](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming)。\n",
    "\n",
    "让我们设置模块 2 中的聊天机器人，并展示在图执行期间以不同方式流式传输输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "注意我们用 `call_model` 配合 `RunnableConfig` 来启用按 token 的流式传输。[只有在 Python < 3.11 时才需要这样做](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/)。我们也把它保留下来，以防你在 Colab 中运行本 notebook（Colab 使用 Python 3.x）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "\n",
    "# State\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "\n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "\n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "\n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt\n",
    "    if summary:\n",
    "\n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### 流式传输完整状态\n",
    "\n",
    "现在，让我们讨论如何[流式传输图状态](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming)。\n",
    "\n",
    "`.stream` 和 `.astream` 分别是同步与异步方法，用于流式返回结果。\n",
    " \n",
    "LangGraph 为[图状态](https://langchain-ai.github.io/langgraph/how-tos/stream-values/)提供了几种[不同的流式模式](https://langchain-ai.github.io/langgraph/how-tos/stream-values/)：\n",
    " \n",
    "* `values`：在每个节点执行后流式传回图的完整状态。\n",
    "* `updates`：在每个节点执行后仅流式传回对图状态的更新。\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "来看看 `stream_mode=\"updates\"`。\n",
    "\n",
    "因为我们使用 `updates` 进行流式传输，所以只能看到每个节点运行后对状态的更新。\n",
    "\n",
    "每个 `chunk` 是一个字典，键是 `node_name`，值是更新后的状态。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hello, Lance! ٩(◕‿◕｡)۶ How's your day going? I'd love to hear what's on your mind or help with anything you need!\", additional_kwargs={}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': 'cfedf183-e22b-4c0a-803f-afac4b16d791', 'token_usage': {'input_tokens': 13, 'output_tokens': 38, 'total_tokens': 51, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--be65ae1a-0056-4aa2-ad04-23092f41172e-0')}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "接下来我们只打印状态更新。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi again, Lance! ٩(◕‿◕｡)۶ I remember you—welcome back! Is there something fun or interesting you'd like to chat about? Or maybe a question I can help with? 😊\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"\n",
    "):\n",
    "    chunk[\"conversation\"][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "现在看看 `stream_mode=\"values\"`。\n",
    "\n",
    "这是 `conversation` 节点运行后图的`完整状态`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! ٩(◕‿◕｡)۶ How's your day going? I'd love to hear what's on your mind or help with anything you need!\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event[\"messages\"]:\n",
    "        m.pretty_print()\n",
    "    print(\"---\" * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### 流式传输 token\n",
    "\n",
    "我们通常希望流式传输的不仅仅是图状态。\n",
    "\n",
    "特别是调用聊天模型时，常见需求是实时流式传回生成的 token。\n",
    "\n",
    "我们可以使用[`.astream_events` 方法](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node)来实现，它会按事件发生的顺序从节点中流式传回事件！\n",
    "\n",
    "每个事件都是一个包含多个键的字典：\n",
    " \n",
    "* `event`：事件的类型。\n",
    "* `name`：事件名称。\n",
    "* `data`：与事件相关的数据。\n",
    "* `metadata`：包含 `langgraph_node`，即发出事件的节点。\n",
    "\n",
    "来看一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatTongyi\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events(\n",
    "    {\"messages\": [input_message]}, config, version=\"v2\"\n",
    "):\n",
    "    print(\n",
    "        f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "关键在于，图中的聊天模型所产生的 token 事件类型为 `on_chat_model_stream`。\n",
    "\n",
    "我们可以用 `event['metadata']['langgraph_node']` 来筛选想要流式传输的节点。\n",
    "\n",
    "我们还可以用 `event['data']` 获取每个事件的实际数据，在这个例子中是 `AIMessageChunk`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='San Francisco ', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='49ers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** are a professional American', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' football team based in the San', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco Bay Area.', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' They compete in the National', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Football League (NFL) as', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' a member of the', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **National Football Conference (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='NFC) West division', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='**. The team', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' was established in **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1946', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** as part of the All', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='-America Football Conference', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' (AAFC) and', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' joined the NFL in **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1950', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** when the AA', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='FC merged with the NFL', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n### Key Facts:\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='- **Home Stadium', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=\"**: Levi's®\", additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium in Santa Clara', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', California (opened', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' in 201', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='4).\\n- **Team', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Colors**: Cardinal red', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', gold, and black', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n- **Team', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Name Origin**: The name', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' \"49ers\" refers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to the **California Gold', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Rush of 1', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='849**, a', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' pivotal event in the', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' state’s history.', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Miners who came', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to California during that', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' time were known as', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' \"Forty-N', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='iners.\"\\n\\n---\\n\\n### Historical', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Success\\n\\nThe 49', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ers are one of the', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' most successful franchises in NFL', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' history, particularly during', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' the 1980', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='s and 199', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='0s.\\n\\n#### Super', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl Championships (5):\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='- **Super Bowl XVI', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (198', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1 season) – Def', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='eated Cincinnati Bengals,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 26–', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='21\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowl XIX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (1984', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=') – Beat Miami', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Dolphins, 38', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='–16\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowl XXIII', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (1988', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=') – Defeated Cincinnati Bengals', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', 20–1', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='6\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowl XXIV', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (1989', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=') – Crushed Denver', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Broncos, 5', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='5–10\\n-', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **Super Bowl L', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='IV** (2', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='019 season', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=') – Lost to', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas City Chiefs,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 31–2', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='0  \\n  *(Note:', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Though they lost,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' they reached the big', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' game. Their last', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' win was Super Bowl XXIV', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.)*\\n\\nWait', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' — correction:\\n- The', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 49ers have', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **won 5 Super', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Bowls** (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='XVI, XIX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', XXIII, XXIV', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', and **LIV', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** is incorrect;', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' actually, their fifth', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' win was **XX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='IV**).  \\n ', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' ✅ Correct list of', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' wins:\\n  - XVI', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' (198', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1)\\n  - X', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='IX (1984', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=')\\n  - XX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='III (1988', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=')\\n  - XXIV (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1989)\\n ', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' - **And no', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' fifth win** —', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' actually, **they have won', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 5 Super Bow', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ls**, but their', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **last victory was Super', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl XXIX (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='1994', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' season)**, where', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' they beat the San Diego Chargers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 49–2', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='6.\\n\\n✅ Final', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' corrected list:\\n-', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **Super Bowl XVI**', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' (1981)\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='- **Super Bowl X', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='IX** (1', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='984)\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowl XXIII', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (1988', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=')\\n- **Super Bowl XX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='IV** (198', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='9)\\n- **Super Bowl', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' XXIX** (1', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='994)\\n\\nSo,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' **five championships**,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' all under two legendary figures', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=': **Bill Walsh', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** and **George', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Seifert**.\\n\\n---\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='### Legendary Figures\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='- **Joe Montana', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** – Hall of Fame', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback, known for his clutch', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' performances and four Super', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl wins. Famous', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' for “The Catch', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='” in the 19', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='81 NFC Championship', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Game.\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Jerry Rice** – Wid', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ely considered the greatest', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' wide receiver in NFL', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' history. Holds numerous', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' records, including most', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' career touchdowns and receiving', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' yards.\\n- **Ron', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='nie Lott** – Hall', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' of Fame defensive back', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' known for toughness and leadership', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n- **Steve', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Young** – S', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ucceeded Montana, won', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Super Bowl XXIX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', and was also a dual', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='-threat QB.\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Bill Walsh** –', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Innovative head coach and', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' architect of the “', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='West Coast Offense.”', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Coached the team', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to three Super Bowl wins', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n- **George', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Seifert** – Head', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' coach who led the team to', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' two Super Bowl victories (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='XXIV and XXIX', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=').\\n\\n---\\n\\n### Recent Years', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\nUnder head coach **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Kyle Shanahan** (', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='son of former Redskins', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' coach Mike Shanahan) and', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback **Brock', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Purdy** (the', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' \"Mr. Ir', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='relevant\" turned starter', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='), the 49ers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' have returned to prominence', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' in the 2', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='020s.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Recent highlights:\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowl LIV', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** (201', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='9 season): Lost', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to Kansas City Chiefs,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 31–', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='20.\\n- **N', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='FC Champions in 20', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='23**: Reached Super', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl LVIII, where', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' they lost in overtime', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to the Kansas City Chiefs,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 25–22', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\nDespite not winning', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' a Super Bowl since', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 1994', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', the 49ers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' remain a consistently competitive', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' team with a strong front', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' office, coaching staff', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', and passionate fan base.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='---\\n\\n### Rival', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ries\\n\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Dallas Cowboys** – Historic', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 197', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='0s–199', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='0s rivalry,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' especially in NFC Championship', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' games.\\n- **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='Los Angeles Rams** – Division', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='al and geographic rivalry,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' intensified after the Rams', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' returned to LA in', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 2016', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='.\\n- **Seattle', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks** – F', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ierce NFC West battles', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=', especially during the', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' 2010', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='s.\\n\\n---\\n\\n### Fan', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Base & Culture\\n\\nThe ', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='49ers boast', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' a massive and loyal fan base', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' across Northern California and beyond', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='. Tailgating at', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Levi’s Stadium,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' the “Red Faith', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='ful,” and traditions', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' like the “Gold', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' Rush” cheerleaders', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' contribute to a vibrant game', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='-day atmosphere.\\n\\nKnown', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' for innovation both on', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' and off the field,', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' the 49ers were', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' among the first NFL teams', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' to embrace advanced analytics', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' and technology in training', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' and operations.\\n\\n---\\n\\n', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='In summary, the **', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='San Francisco 49ers', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='** are an iconic NFL franchise', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' with a rich legacy', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' of excellence, legendary', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' players, and a', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' continued pursuit of championship', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content=' glory.', additional_kwargs={}, response_metadata={}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'request_id': '32a199ba-4603-443d-b251-fb5239a697e1', 'token_usage': {'input_tokens': 18, 'output_tokens': 1175, 'total_tokens': 1193, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--c3f7ff0f-0444-4900-b133-ff189a45961b')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = \"conversation\"\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events(\n",
    "    {\"messages\": [input_message]}, config, version=\"v2\"\n",
    "):\n",
    "    # Get chat model tokens from a particular node\n",
    "    if (\n",
    "        event[\"event\"] == \"on_chat_model_stream\"\n",
    "        and event[\"metadata\"].get(\"langgraph_node\", \"\") == node_to_stream\n",
    "    ):\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "如上所示，只要使用 `chunk` 键就能拿到 `AIMessageChunk`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| **|San Francisco |49ers|** are a professional American| football team based in the San| Francisco Bay Area.| They compete in the National| Football League (NFL) as| a member of the| **National Football Conference (|NFC) West division|**. The team| plays its home games| at **Levi|'s Stadium** in| Santa Clara, California,| which opened in 2|014.\n",
      "\n",
      "|### History and Origins|\n",
      "- **Founded**: |1946| (as a charter| member of the All|-America Football Conference|, or AAFC)\n",
      "-| **Joined NFL**: |1950|, after the AA|FC merged with the NFL|\n",
      "- **Name Origin|**: The name \"49|ers\" refers to the **|California Gold Rush of| 184|9**, when thousands| of prospectors f|locked to northern California in| search of gold.\n",
      "\n",
      "### Championships| and Success\n",
      "The| 49ers are one| of the most successful teams| in NFL history:\n",
      "|- **Super Bowl Wins|**: 5 championships| (tied for| second-most all-time| with the Cowboys and Packers|; behind only the Steelers with| 6)\n",
      " | - **Super Bowl XVI|** (19|81 season):| Defeated the Cincinnati Bengals| 26–|21\n",
      "  - **|Super Bowl XIX|** (1984|): Beat the Miami Dolphins| 38–1|6\n",
      "  -| **Super Bowl XXIII|** (1988|): Won 20–|16 over the| Cincinnati Bengals on a last|-minute Joe Montana touchdown| pass\n",
      "  -| **Super Bowl XXIV|** (198|9): Dominated the Denver| Broncos 55|–10\n",
      " | - **Super Bowl L|IV** (2|019 season|): Lost to the| Kansas City Chiefs |31–2|0 (note: this| was a loss; their| last win was Super| Bowl XXIX)\n",
      "\n",
      "|> ✅ Their| five Super Bowl victories| came under two legendary head| coaches:\n",
      "> - **|Bill Walsh** (3| titles: XVI,| XIX, XXIII)| – known for pioneering| the \"West Coast| Offense\"\n",
      "> - **|George Seifert|** (2 titles: XX|IV, XXIX|)\n",
      "\n",
      "### Notable Players\n",
      "|The 49|ers have featured some| of the greatest players in NFL| history:\n",
      "- **Joe| Montana** – Hall| of Fame quarterback, |4-time Super Bowl champion|, known for his clutch| performances\n",
      "- **|Jerry Rice** – Wid|ely considered the greatest| wide receiver ever;| holds numerous NFL records\n",
      "-| **Ronnie L|ott** – Legendary| safety and hard-h|itting defensive back\n",
      "- **|Steve Young** – Hall| of Fame QB who| succeeded Montana; won Super| Bowl XXIX MVP|\n",
      "- **Law|rence Taylor** (|opponent, but iconic| rivalry), though more| associated with the Giants|\n",
      "\n",
      "More recent stars| include:\n",
      "- **|Colin Kaepernick** – Starting| QB from 20|12–201|6, known for leading| comeback wins and later| for kneeling during the| national anthem to protest racial| injustice\n",
      "- **Jimmy| Garoppolo** – Starting| QB during late 20|10s/|early 20|20s\n",
      "- **|Brock Purdy|** – Current starting| quarterback (as of 2|023–20|24), the| \"Mr. Ir|relevant\" pick who| rose to prominence\n",
      "|- **Nick B|osa** – Star| defensive end, multiple|-time Pro Bowler and All|-Pro\n",
      "- **|George Kittle** – One| of the top tight| ends in the league|\n",
      "\n",
      "### Head Co|aches\n",
      "- **Bill| Walsh** (197|9–198|8): Architect of| the team’s dynasty|, innovator of offensive| strategy\n",
      "- **|George Seifert**| (198|9–1996|): Continued success,| won two Super Bow|ls\n",
      "- **Kyle| Shanahan** (|2017–present|): Son of former| NFL coach Mike Shan|ahan; known for creative| offensive schemes. Led| the team to Super Bowl L|IV and Super Bowl| LVIII (both| losses as of |2024)\n",
      "\n",
      "|### Rivalries\n",
      "|- **Dallas Cowboys** –| Historic NFC rivalry from| the 197|0s–199|0s, especially during playoff| battles\n",
      "- **|Seattle Seahawks** – Int|ensified in the 2|010s as| both were top NFC| teams\n",
      "- **Los| Angeles Rams** – Division|al rival; renewed| in recent years with competitive| matchups\n",
      "\n",
      "### Culture| and Legacy\n",
      "- The| 49ers helped| define modern NFL excellence| in the 1|980s and |1990s.\n",
      "|- Their style of| play under Bill Walsh emphasized| precision passing, timing|, and quarterback decision|-making.\n",
      "- The team| has a large,| passionate fan base known| as the \"Fa|ithful.\"\n",
      "- Levi|'s Stadium is one| of the most techn|ologically advanced venues in sports|.\n",
      "\n",
      "As of the| early 20|20s, the| 49ers remain| a consistent contender in the| NFL, frequently reaching the playoffs| and competing for NFC| and Super Bowl titles| under Kyle Shanahan and| general manager John Lynch|.\n",
      "\n",
      "They continue to be a| cornerstone franchise in NFL history —| blending tradition, innovation,| and a relentless pursuit of excellence|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events(\n",
    "    {\"messages\": [input_message]}, config, version=\"v2\"\n",
    "):\n",
    "    # Get chat model tokens from a particular node\n",
    "    if (\n",
    "        event[\"event\"] == \"on_chat_model_stream\"\n",
    "        and event[\"metadata\"].get(\"langgraph_node\", \"\") == node_to_stream\n",
    "    ):\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### 搭配 LangGraph API 的流式传输\n",
    "\n",
    "**⚠️ 免责声明**\n",
    "\n",
    "自从录制这些视频以来，我们已经更新了 Studio，使其可以在本地运行并在浏览器中打开。现在推荐的方式是以这种形式运行 Studio（而不是像视频中展示的桌面应用）。关于本地开发服务器请查看[这里](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server)的文档，关于本地 Studio 的运行方式请查看[这里](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)。在本模块的 `/studio` 目录中，在终端运行以下命令即可启动本地开发服务器：\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "你应该会看到如下输出：\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "在浏览器中访问 Studio UI：`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`。\n",
    "\n",
    "LangGraph API [支持编辑图状态](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    raise Exception(\n",
    "        \"Unfortunately LangGraph Studio is currently not supported on Google Colab\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "像之前那样，让我们[流式传输 `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '01998616-d7bb-7464-908d-f54e7562fb9d', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e0d71cb-2425-42d2-a1f2-816611ed074c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e0d71cb-2425-42d2-a1f2-816611ed074c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'a0c4f37f-7ed7-41a4-83e0-2ff894103aac', 'token_usage': {'input_tokens': 350, 'output_tokens': 24, 'total_tokens': 374, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--569da51f-3f96-4b9c-817d-67de7e1bca5d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e0d71cb-2425-42d2-a1f2-816611ed074c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'a0c4f37f-7ed7-41a4-83e0-2ff894103aac', 'token_usage': {'input_tokens': 350, 'output_tokens': 24, 'total_tokens': 374, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--569da51f-3f96-4b9c-817d-67de7e1bca5d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '76ea04d6-dcb2-48d3-8a34-5243c9e33164', 'tool_call_id': 'call_4899a42be33b40c7b6a8f8', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e0d71cb-2425-42d2-a1f2-816611ed074c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'a0c4f37f-7ed7-41a4-83e0-2ff894103aac', 'token_usage': {'input_tokens': 350, 'output_tokens': 24, 'total_tokens': 374, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--569da51f-3f96-4b9c-817d-67de7e1bca5d-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_4899a42be33b40c7b6a8f8', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '76ea04d6-dcb2-48d3-8a34-5243c9e33164', 'tool_call_id': 'call_4899a42be33b40c7b6a8f8', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': '71b55a56-81e6-40c2-9a33-9d95ac9d229f', 'token_usage': {'input_tokens': 389, 'output_tokens': 13, 'total_tokens': 402, 'prompt_tokens_details': {'cached_tokens': 0}}}, 'type': 'ai', 'name': None, 'id': 'run--0fcf8518-3e6b-4e3b-95c7-047977893e6e-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "流式传回的对象包含： \n",
    "\n",
    "* `event`：事件类型\n",
    "* `data`：状态\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='75e72bd9-dbc2-4a49-a46f-8b6c4549181d'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': None, 'tool_calls': [{'index': 0, 'id': 'call_9838b3bb857f4947bb33c0', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]} response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '05803dbc-843b-409a-973b-e9054b45525f', 'token_usage': {'input_tokens': 350, 'output_tokens': 24, 'total_tokens': 374, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--b3c745ec-b07c-4d9b-9360-c452149b0690-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_9838b3bb857f4947bb33c0', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='3923a49c-098c-4752-9016-f1a163de25a0' tool_call_id='call_9838b3bb857f4947bb33c0'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': None} response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': '607b202c-013d-4ab0-9346-35ef21a8bf26', 'token_usage': {'input_tokens': 389, 'output_tokens': 13, 'total_tokens': 402, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--decdb3ef-7995-4bf7-a256-80e0a2ca934f-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    messages = event.data.get(\"messages\", None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print(\"=\" * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "API 还支持一些新的流式模式。\n",
    "\n",
    "例如，我们可以使用[`messages` 模式](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/)来更好地处理上述场景！\n",
    "\n",
    "这种模式目前假设你的图里有一个 `messages` 键，并且它是消息列表。\n",
    "\n",
    "使用 `messages` 模式发出的所有事件都有两个属性：\n",
    "\n",
    "* `event`：事件名称\n",
    "* `data`：与事件相关的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "我们可以看到几个事件： \n",
    "\n",
    "* `metadata`：有关运行的元数据\n",
    "* `messages/complete`：完整成形的消息 \n",
    "* `messages/partial`：聊天模型的 token\n",
    "\n",
    "你可以在[这里](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages)进一步了解这些事件的类型。\n",
    "\n",
    "现在我们来展示如何流式传输这些消息。 \n",
    "\n",
    "我们会定义一个辅助函数，以便更好地格式化消息中的工具调用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 01998687-ebed-77be-966d-56bda4002857\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_93788bfc8f0b4555a9adc8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_93788bfc8f0b4555a9adc8call_93788bfc8f0b4555a9adc8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_93788bfc8f0b4555a9adc8call_93788bfc8f0b4555a9adc8call_93788bfc8f0b4555a9adc8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "\n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
