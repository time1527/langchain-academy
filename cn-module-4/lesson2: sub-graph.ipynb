{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec1671c",
   "metadata": {},
   "source": [
    "[![在 Colab 中打开](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![在 LangChain Academy 中打开](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3db85080-2299-4885-a2f6-fffa6a09a238",
   "metadata": {},
   "source": [
    "# 子图\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们正在逐步构建一个多智能体研究助手，它将本课程的所有模块串联在一起。\n",
    "\n",
    "我们刚刚介绍了并行化，这是 LangGraph 控制能力的一个关键主题。\n",
    "\n",
    "## 目标\n",
    "\n",
    "现在，我们要[学习子图](https://langchain-ai.github.io/langgraph/how-tos/subgraph/#simple-example)。\n",
    "\n",
    "## 状态\n",
    "\n",
    "子图让你可以在图的不同部分创建并管理不同的状态。\n",
    "\n",
    "这对多智能体系统尤其有用，因为每个智能体团队通常都有自己的状态。\n",
    "\n",
    "我们来看一个简化示例：\n",
    "\n",
    "* 我有一个接收日志的系统\n",
    "* 不同的智能体会执行两个独立的子任务（总结日志、查找失败模式）\n",
    "* 我希望这两个操作在两个不同的子图中完成\n",
    "\n",
    "理解图之间如何通信是关键！\n",
    "\n",
    "简而言之，通信是通过**重叠的键**完成的：\n",
    "\n",
    "* 子图可以访问父图提供的 `docs`\n",
    "* 父图可以访问子图返回的 `summary/failure_report`\n",
    "\n",
    "![subgraph.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb1abf89f2d847ee6f1ff_sub-graph1.png)\n",
    "\n",
    "## 输入\n",
    "\n",
    "我们先为要传入图中的日志定义一个 schema。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2954e8c6-496f-4394-b56a-681608bf65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U  langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e413ba-e376-4a5f-a666-2d2154aa6fe2",
   "metadata": {},
   "source": [
    "我们将使用 [LangSmith](https://docs.smith.langchain.com/) 来[追踪](https://docs.smith.langchain.com/concepts/tracing)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b26c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efaf8bb-f675-4c0b-a575-89c7e2987a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Optional, Annotated\n",
    "\n",
    "\n",
    "# The structure of the logs\n",
    "# 结构体，作为输入\n",
    "class Log(TypedDict):\n",
    "    id: str\n",
    "    question: str\n",
    "    docs: Optional[List]\n",
    "    answer: str\n",
    "    grade: Optional[int]\n",
    "    grader: Optional[str]\n",
    "    feedback: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15825627-78c2-4ba0-ad11-95e4afdb771d",
   "metadata": {},
   "source": [
    "## 子图\n",
    "\n",
    "下面是使用 `FailureAnalysisState` 的失败分析子图。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32986a9-6d11-4646-b2c0-fbae4f524579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "# Failure Analysis Sub-graph\n",
    "# 失败分析状态，作为中间状态\n",
    "class FailureAnalysisState(TypedDict):\n",
    "    cleaned_logs: List[Log]\n",
    "    failures: List[Log]\n",
    "    fa_summary: str\n",
    "    processed_logs: List[str]\n",
    "\n",
    "\n",
    "# 失败分析输出状态，作为输出状态\n",
    "class FailureAnalysisOutputState(TypedDict):\n",
    "    fa_summary: str\n",
    "    processed_logs: List[str]\n",
    "\n",
    "\n",
    "def get_failures(state):\n",
    "    \"\"\"获取包含失败信息的日志\n",
    "\n",
    "    此函数从清理过的日志中筛选出包含等级（grade）信息的日志条目，\n",
    "    这些条目通常表示某种形式的失败或评估结果。\n",
    "\n",
    "    参数:\n",
    "        state (dict): 包含系统状态的字典，必须包含'cleaned_logs'键\n",
    "\n",
    "    返回:\n",
    "        dict: 包含一个键为'failures'的字典，对应值为筛选出的失败日志列表\n",
    "    \"\"\"\n",
    "    cleaned_logs = state[\"cleaned_logs\"]  # 从状态中提取清理过的日志\n",
    "    failures = [log for log in cleaned_logs if \"grade\" in log]  # 筛选包含'grade'的日志\n",
    "    return {\"failures\": failures}  # 返回失败日志列表\n",
    "\n",
    "\n",
    "def generate_summary(state):\n",
    "    \"\"\"生成失败日志的摘要\n",
    "\n",
    "    此函数从系统状态中提取失败日志，并为这些失败生成汇总摘要，\n",
    "    同时为每个失败日志创建处理记录标识。\n",
    "\n",
    "    参数:\n",
    "        state (dict): 包含系统状态的字典，必须包含'failures'键，对应值为失败日志列表\n",
    "\n",
    "    返回:\n",
    "        dict: 包含两个键的字典\n",
    "            - 'fa_summary': 失败分析的汇总摘要\n",
    "            - 'processed_logs': 处理过的失败日志标识符列表\n",
    "    \"\"\"\n",
    "    failures = state[\"failures\"]  # 从状态中提取失败日志列表\n",
    "    # Add fxn: fa_summary = summarize(failures)  # 注释表明这里原本计划调用summarize函数\n",
    "    fa_summary = \"Poor quality retrieval of Chroma documentation.\"  # 失败分析的汇总摘要\n",
    "    return {\n",
    "        \"fa_summary\": fa_summary,  # 返回汇总摘要\n",
    "        \"processed_logs\": [\n",
    "            # 为每个失败日志创建处理记录标识符\n",
    "            f\"failure-analysis-on-log-{failure['id']}\"\n",
    "            for failure in failures\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "fa_builder = StateGraph(\n",
    "    state_schema=FailureAnalysisState, output_schema=FailureAnalysisOutputState\n",
    ")\n",
    "fa_builder.add_node(\"get_failures\", get_failures)\n",
    "fa_builder.add_node(\"generate_summary\", generate_summary)\n",
    "fa_builder.add_edge(START, \"get_failures\")\n",
    "fa_builder.add_edge(\"get_failures\", \"generate_summary\")\n",
    "fa_builder.add_edge(\"generate_summary\", END)\n",
    "\n",
    "graph = fa_builder.compile()\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83f44c-0bb9-48c6-afec-dad536e608fa",
   "metadata": {},
   "source": [
    "这是使用 `QuestionSummarizationState` 的问题汇总子图。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7149000c-ffb6-4834-bd9e-d35b36c524e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization subgraph\n",
    "# 问题摘要状态，作为中间状态\n",
    "class QuestionSummarizationState(TypedDict):\n",
    "    cleaned_logs: List[Log]\n",
    "    qs_summary: str\n",
    "    report: str\n",
    "    processed_logs: List[str]\n",
    "\n",
    "\n",
    "# 问题摘要输出状态，作为输出状态\n",
    "class QuestionSummarizationOutputState(TypedDict):\n",
    "    report: str\n",
    "    processed_logs: List[str]\n",
    "\n",
    "\n",
    "def generate_summary(state):\n",
    "    \"\"\"生成日志内容的总结摘要\n",
    "\n",
    "    此函数从清理过的日志中提取信息，并生成关于问题重点的摘要，\n",
    "    同时为每个处理过的日志创建唯一标识。\n",
    "\n",
    "    参数:\n",
    "        state (dict): 包含系统状态的字典，必须包含'cleaned_logs'键，对应值为清理过的日志列表\n",
    "\n",
    "    返回:\n",
    "        dict: 包含两个键的字典\n",
    "            - 'qs_summary': 问题重点的总结摘要\n",
    "            - 'processed_logs': 处理过的日志标识符列表\n",
    "    \"\"\"\n",
    "    cleaned_logs = state[\"cleaned_logs\"]  # 从状态中提取清理过的日志列表\n",
    "    # Add fxn: summary = summarize(generate_summary)  # 注释表明这里原本计划调用summarize函数\n",
    "    summary = \"Questions focused on usage of ChatOllama and Chroma vector store.\"  # 生成的问题重点摘要\n",
    "    return {\n",
    "        \"qs_summary\": summary,  # 返回问题摘要\n",
    "        \"processed_logs\": [\n",
    "            # 为每个清理过的日志创建处理记录标识符\n",
    "            f\"summary-on-log-{log['id']}\"\n",
    "            for log in cleaned_logs\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def send_to_slack(state):\n",
    "    \"\"\"生成用于发送到Slack的报告\n",
    "\n",
    "    此函数从系统状态中提取问题摘要，并基于该摘要生成一个\n",
    "    可发送到Slack的报告内容。\n",
    "\n",
    "    参数:\n",
    "        state (dict): 包含系统状态的字典，必须包含'qs_summary'键，对应值为问题摘要\n",
    "\n",
    "    返回:\n",
    "        dict: 包含一个键为'report'的字典，对应值为生成的报告内容\n",
    "    \"\"\"\n",
    "    qs_summary = state[\"qs_summary\"]  # 从状态中提取问题摘要\n",
    "    # Add fxn: report = report_generation(qs_summary)  # 注释表明这里原本计划调用report_generation函数\n",
    "    report = \"foo bar baz\"  # 生成的报告内容（当前为示例文本）\n",
    "    return {\"report\": report}  # 返回生成的报告\n",
    "\n",
    "\n",
    "qs_builder = StateGraph(\n",
    "    QuestionSummarizationState, output_schema=QuestionSummarizationOutputState\n",
    ")\n",
    "qs_builder.add_node(\"generate_summary\", generate_summary)\n",
    "qs_builder.add_node(\"send_to_slack\", send_to_slack)\n",
    "qs_builder.add_edge(START, \"generate_summary\")\n",
    "qs_builder.add_edge(\"generate_summary\", \"send_to_slack\")\n",
    "qs_builder.add_edge(\"send_to_slack\", END)\n",
    "\n",
    "graph = qs_builder.compile()\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a5baf-beab-4927-807a-3e6a5ad3d202",
   "metadata": {},
   "source": [
    "## 将子图加入父图\n",
    "\n",
    "现在我们可以把所有内容组合到一起。\n",
    "\n",
    "我们使用 `EntryGraphState` 创建父图。\n",
    "\n",
    "然后把子图作为节点加入！\n",
    "\n",
    "```\n",
    "entry_builder.add_node(\"question_summarization\", qs_builder.compile())\n",
    "entry_builder.add_node(\"failure_analysis\", fa_builder.compile())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587c8fe1-1ae8-411e-a55d-cac299026646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry Graph\n",
    "class EntryGraphState(TypedDict):\n",
    "    raw_logs: List[Log]\n",
    "    cleaned_logs: Annotated[List[Log], add]  # This will be USED BY in BOTH sub-graphs\n",
    "    fa_summary: str  # This will only be generated in the FA sub-graph\n",
    "    report: str  # This will only be generated in the QS sub-graph\n",
    "    processed_logs: Annotated[\n",
    "        List[int], add\n",
    "    ]  # This will be generated in BOTH sub-graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4da397-310c-4453-969a-e0ae2cc75db8",
   "metadata": {},
   "source": [
    "但是，如果 `cleaned_logs` 只是作为输入传入每个子图而不会被修改，为什么还需要 reducer 呢？\n",
    "\n",
    "```\n",
    "cleaned_logs: Annotated[List[Log], add] # This will be USED BY in BOTH sub-graphs\n",
    "```\n",
    "\n",
    "这是因为子图的输出状态会包含**所有键**，即使它们没有被修改。\n",
    "\n",
    "子图是并行运行的。\n",
    "\n",
    "由于并行的子图会返回同名键，我们需要像 `operator.add` 这样的 reducer 来合并每个子图传回的值。\n",
    "\n",
    "不过，我们可以利用之前提到的另一个概念来规避这个问题。\n",
    "\n",
    "只要为每个子图创建输出状态 schema，并让它们输出不同的键即可。\n",
    "\n",
    "我们其实不需要每个子图都输出 `cleaned_logs`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50092b9b-70c1-41b1-a74a-254683e28ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry Graph\n",
    "class EntryGraphState(TypedDict):\n",
    "    raw_logs: List[Log]\n",
    "    cleaned_logs: List[Log]\n",
    "    fa_summary: str  # This will only be generated in the FA sub-graph\n",
    "    report: str  # This will only be generated in the QS sub-graph\n",
    "    processed_logs: Annotated[\n",
    "        List[int], add\n",
    "    ]  # This will be generated in BOTH sub-graphs\n",
    "\n",
    "\n",
    "def clean_logs(state):\n",
    "    # Get logs\n",
    "    raw_logs = state[\"raw_logs\"]\n",
    "    # Data cleaning raw_logs -> docs\n",
    "    cleaned_logs = raw_logs\n",
    "    return {\"cleaned_logs\": cleaned_logs}\n",
    "\n",
    "\n",
    "entry_builder = StateGraph(EntryGraphState)\n",
    "entry_builder.add_node(\"clean_logs\", clean_logs)\n",
    "entry_builder.add_node(\"question_summarization\", qs_builder.compile())\n",
    "entry_builder.add_node(\"failure_analysis\", fa_builder.compile())\n",
    "\n",
    "entry_builder.add_edge(START, \"clean_logs\")\n",
    "entry_builder.add_edge(\"clean_logs\", \"failure_analysis\")\n",
    "entry_builder.add_edge(\"clean_logs\", \"question_summarization\")\n",
    "entry_builder.add_edge(\"failure_analysis\", END)\n",
    "entry_builder.add_edge(\"question_summarization\", END)\n",
    "\n",
    "graph = entry_builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Setting xray to 1 will show the internal structure of the nested graph\n",
    "# display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17af1254-4e75-4349-9a79-295f4ec95016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_logs': [{'id': '1',\n",
       "   'question': 'How can I import ChatOllama?',\n",
       "   'answer': \"To import ChatOllama, use: 'from langchain_community.chat_models import ChatOllama.'\"},\n",
       "  {'id': '2',\n",
       "   'question': 'How can I use Chroma vector store?',\n",
       "   'answer': 'To use Chroma, define: rag_chain = create_retrieval_chain(retriever, question_answer_chain).',\n",
       "   'grade': 0,\n",
       "   'grader': 'Document Relevance Recall',\n",
       "   'feedback': 'The retrieved documents discuss vector stores in general, but not Chroma specifically'}],\n",
       " 'cleaned_logs': [{'id': '1',\n",
       "   'question': 'How can I import ChatOllama?',\n",
       "   'answer': \"To import ChatOllama, use: 'from langchain_community.chat_models import ChatOllama.'\"},\n",
       "  {'id': '2',\n",
       "   'question': 'How can I use Chroma vector store?',\n",
       "   'answer': 'To use Chroma, define: rag_chain = create_retrieval_chain(retriever, question_answer_chain).',\n",
       "   'grade': 0,\n",
       "   'grader': 'Document Relevance Recall',\n",
       "   'feedback': 'The retrieved documents discuss vector stores in general, but not Chroma specifically'}],\n",
       " 'fa_summary': 'Poor quality retrieval of Chroma documentation.',\n",
       " 'report': 'foo bar baz',\n",
       " 'processed_logs': ['failure-analysis-on-log-2',\n",
       "  'summary-on-log-1',\n",
       "  'summary-on-log-2']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy logs\n",
    "question_answer = Log(\n",
    "    id=\"1\",\n",
    "    question=\"How can I import ChatOllama?\",\n",
    "    answer=\"To import ChatOllama, use: 'from langchain_community.chat_models import ChatOllama.'\",\n",
    ")\n",
    "\n",
    "question_answer_feedback = Log(\n",
    "    id=\"2\",\n",
    "    question=\"How can I use Chroma vector store?\",\n",
    "    answer=\"To use Chroma, define: rag_chain = create_retrieval_chain(retriever, question_answer_chain).\",\n",
    "    grade=0,\n",
    "    grader=\"Document Relevance Recall\",\n",
    "    feedback=\"The retrieved documents discuss vector stores in general, but not Chroma specifically\",\n",
    ")\n",
    "\n",
    "raw_logs = [question_answer, question_answer_feedback]\n",
    "graph.invoke({\"raw_logs\": raw_logs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192d228-4d3d-4fb0-8bea-26772c3d2e0b",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "来看一下 LangSmith trace：\n",
    "\n",
    "https://smith.langchain.com/public/f8f86f61-1b30-48cf-b055-3734dfceadf2/r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e836d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
