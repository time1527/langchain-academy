{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4f701",
   "metadata": {},
   "source": [
    "[![在 Colab 中打开](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/map-reduce.ipynb) [![在 LangChain Academy 中打开](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239947-lesson-3-map-reduce)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36737349-c949-4d64-9aa3-3767cbd02ad1",
   "metadata": {},
   "source": [
    "# Map-Reduce\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们正在逐步构建一个多智能体研究助手，它会把本课程中的所有模块串联起来。\n",
    "\n",
    "为了构建这个多智能体助手，我们已经介绍了几个 LangGraph 的可控性主题。\n",
    "\n",
    "我们刚刚学习了并行化和子图。\n",
    "\n",
    "## 目标\n",
    "\n",
    "接下来，我们将[学习 map reduce](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24e95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff57cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd868a",
   "metadata": {},
   "source": [
    "我们将使用 [LangSmith](https://docs.smith.langchain.com/) 来[追踪](https://docs.smith.langchain.com/concepts/tracing)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe9b9f-4375-4bca-8e32-7d57cb861469",
   "metadata": {},
   "source": [
    "## 问题\n",
    "\n",
    "Map-Reduce 操作对于高效的任务拆解和并行处理至关重要。\n",
    "\n",
    "它包含两个阶段：\n",
    "\n",
    "(1) `Map` —— 将任务拆分成更小的子任务，并行处理每个子任务。\n",
    "\n",
    "(2) `Reduce` —— 聚合所有并行子任务的结果。\n",
    "\n",
    "我们来设计一个系统，完成两件事：\n",
    "\n",
    "(1) `Map` —— 围绕某个主题生成一组笑话。\n",
    "\n",
    "(2) `Reduce` —— 从列表中选出最好笑的一个。\n",
    "\n",
    "我们会使用 LLM 来生成笑话并进行挑选。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994cf903-1ed6-4ae2-b32a-7891a2808f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Prompts we will use\n",
    "subjects_prompt = \"\"\"Generate a list of 3 sub-topics that are all related to this overall topic: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \\n\\n  {jokes}\"\"\"\n",
    "\n",
    "# LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b883cc-3469-4e96-b1a4-deadf7bf3ce5",
   "metadata": {},
   "source": [
    "## 状态\n",
    "\n",
    "### 并行生成笑话\n",
    "\n",
    "首先定义图的入口节点，它将：\n",
    "\n",
    "* 接收用户输入的主题\n",
    "* 基于主题生成一系列笑话题目\n",
    "* 将每个笑话题目发送到我们上面的笑话生成节点\n",
    "\n",
    "我们的状态包含一个 `jokes` 键，用来累积并行笑话生成得到的笑话。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "099218ca-ee78-4291-95a1-87ee61382e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int\n",
    "\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176d1c-4a88-4b0f-a960-ee04a45279bd",
   "metadata": {},
   "source": [
    "生成笑话的题目。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45010efd-ad31-4daa-b77e-aaec79ef0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5296bb0-c163-4e5c-8181-1e305b37442a",
   "metadata": {},
   "source": [
    "这里是关键：我们使用 [Send](https://langchain-ai.github.io/langgraph/concepts/low_level/#send) 为每个题目生成笑话。\n",
    "\n",
    "这非常实用！它可以自动并行地为任意数量的题目生成笑话。\n",
    "\n",
    "* `generate_joke`：图中节点的名称\n",
    "* `{\"subject\": s}`：要发送的状态\n",
    "\n",
    "`Send` 允许你把任意状态传给 `generate_joke`！它不必与 `OverallState` 完全一致。\n",
    "\n",
    "在这个例子里，`generate_joke` 使用它自己的内部状态，我们通过 `Send` 来填充它。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc83e575-11f6-41a9-990a-adb571bcda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847192d-d358-411e-90c0-f06be0738717",
   "metadata": {},
   "source": [
    "### 笑话生成（map）\n",
    "\n",
    "现在定义负责创建笑话的节点 `generate_joke`！\n",
    "\n",
    "我们会把笑话写回 `OverallState` 中的 `jokes` 键。\n",
    "\n",
    "这个键设置了 reducer，用来合并列表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcddc567-73d3-4fb3-bfc5-1bea538f2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02960657-d174-4076-99a8-b3f9eea015f4",
   "metadata": {},
   "source": [
    "### 最佳笑话选择（reduce）\n",
    "\n",
    "接下来添加逻辑，选出最好笑的笑话。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d672870-75e3-4307-bda0-c41a86cbbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd12e-5bff-426e-97f4-c774df998cfb",
   "metadata": {},
   "source": [
    "## 编译\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae6be4b-144e-483c-88ad-ce86d6477a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "# Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e21dc7c9-0add-4125-be76-af701adb874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['Mammals', 'Reptiles', 'Birds']}}\n",
      "{'generate_joke': {'jokes': [\"Why don't birds use Facebook? Because they already have Twitter!\"]}}\n",
      "{'generate_joke': {'jokes': [\"Why don't mammals ever get lost? Because they always follow their 'paws'itive' instincts!\"]}}\n",
      "{'generate_joke': {'jokes': [\"Why don't reptiles ever get invited to card games? Because they always bring the scales!\"]}}\n",
      "{'best_joke': {'best_selected_joke': \"Why don't birds use Facebook? Because they already have Twitter!\"}}\n"
     ]
    }
   ],
   "source": [
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in app.stream({\"topic\": \"animals\"}):\n",
    "    print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a96517e-77ab-46e2-95e2-79168c044e9c",
   "metadata": {},
   "source": [
    "## Studio\n",
    "\n",
    "**⚠️ 免责声明**\n",
    "\n",
    "自从录制这些视频以来，我们已经更新了 Studio，使其可以在本地运行并在浏览器中打开。现在推荐的方式是以这种形式运行 Studio（而不是视频中展示的桌面应用）。关于本地开发服务器请查看[这里](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server)的文档，关于本地 Studio 的运行方式请查看[这里](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)。在本模块的 `/studio` 目录中，在终端运行以下命令即可启动本地开发服务器：\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "你应该会看到如下输出：\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "在浏览器中访问 Studio UI：`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`。\n",
    "\n",
    "让我们在 Studio UI 中加载上面的图，它由 `module-4/studio/map_reduce.py` 定义，并在 `module-4/studio/langgraph.json` 中进行了配置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a5e45-9a4c-43b4-8393-9298b3dcda53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
