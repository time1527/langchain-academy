{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4f701",
   "metadata": {},
   "source": [
    "[![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/map-reduce.ipynb) [![åœ¨ LangChain Academy ä¸­æ‰“å¼€](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239947-lesson-3-map-reduce)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36737349-c949-4d64-9aa3-3767cbd02ad1",
   "metadata": {},
   "source": [
    "# Map-Reduce\n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬æ­£åœ¨é€æ­¥æ„å»ºä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç ”ç©¶åŠ©æ‰‹ï¼Œå®ƒä¼šæŠŠæœ¬è¯¾ç¨‹ä¸­çš„æ‰€æœ‰æ¨¡å—ä¸²è”èµ·æ¥ã€‚\n",
    "\n",
    "ä¸ºäº†æ„å»ºè¿™ä¸ªå¤šæ™ºèƒ½ä½“åŠ©æ‰‹ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†å‡ ä¸ª LangGraph çš„å¯æ§æ€§ä¸»é¢˜ã€‚\n",
    "\n",
    "æˆ‘ä»¬åˆšåˆšå­¦ä¹ äº†å¹¶è¡ŒåŒ–å’Œå­å›¾ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†[å­¦ä¹  map reduce](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24e95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff57cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd868a",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†ä½¿ç”¨ [LangSmith](https://docs.smith.langchain.com/) æ¥[è¿½è¸ª](https://docs.smith.langchain.com/concepts/tracing)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe9b9f-4375-4bca-8e32-7d57cb861469",
   "metadata": {},
   "source": [
    "## é—®é¢˜\n",
    "\n",
    "Map-Reduce æ“ä½œå¯¹äºé«˜æ•ˆçš„ä»»åŠ¡æ‹†è§£å’Œå¹¶è¡Œå¤„ç†è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "å®ƒåŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š\n",
    "\n",
    "(1) `Map` â€”â€” å°†ä»»åŠ¡æ‹†åˆ†æˆæ›´å°çš„å­ä»»åŠ¡ï¼Œå¹¶è¡Œå¤„ç†æ¯ä¸ªå­ä»»åŠ¡ã€‚\n",
    "\n",
    "(2) `Reduce` â€”â€” èšåˆæ‰€æœ‰å¹¶è¡Œå­ä»»åŠ¡çš„ç»“æœã€‚\n",
    "\n",
    "æˆ‘ä»¬æ¥è®¾è®¡ä¸€ä¸ªç³»ç»Ÿï¼Œå®Œæˆä¸¤ä»¶äº‹ï¼š\n",
    "\n",
    "(1) `Map` â€”â€” å›´ç»•æŸä¸ªä¸»é¢˜ç”Ÿæˆä¸€ç»„ç¬‘è¯ã€‚\n",
    "\n",
    "(2) `Reduce` â€”â€” ä»åˆ—è¡¨ä¸­é€‰å‡ºæœ€å¥½ç¬‘çš„ä¸€ä¸ªã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¼šä½¿ç”¨ LLM æ¥ç”Ÿæˆç¬‘è¯å¹¶è¿›è¡ŒæŒ‘é€‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994cf903-1ed6-4ae2-b32a-7891a2808f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Prompts we will use\n",
    "subjects_prompt = \"\"\"Generate a list of 3 sub-topics that are all related to this overall topic: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \\n\\n  {jokes}\"\"\"\n",
    "\n",
    "# LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b883cc-3469-4e96-b1a4-deadf7bf3ce5",
   "metadata": {},
   "source": [
    "## çŠ¶æ€\n",
    "\n",
    "### å¹¶è¡Œç”Ÿæˆç¬‘è¯\n",
    "\n",
    "é¦–å…ˆå®šä¹‰å›¾çš„å…¥å£èŠ‚ç‚¹ï¼Œå®ƒå°†ï¼š\n",
    "\n",
    "* æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜\n",
    "* åŸºäºä¸»é¢˜ç”Ÿæˆä¸€ç³»åˆ—ç¬‘è¯é¢˜ç›®\n",
    "* å°†æ¯ä¸ªç¬‘è¯é¢˜ç›®å‘é€åˆ°æˆ‘ä»¬ä¸Šé¢çš„ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹\n",
    "\n",
    "æˆ‘ä»¬çš„çŠ¶æ€åŒ…å«ä¸€ä¸ª `jokes` é”®ï¼Œç”¨æ¥ç´¯ç§¯å¹¶è¡Œç¬‘è¯ç”Ÿæˆå¾—åˆ°çš„ç¬‘è¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "099218ca-ee78-4291-95a1-87ee61382e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int\n",
    "\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176d1c-4a88-4b0f-a960-ee04a45279bd",
   "metadata": {},
   "source": [
    "ç”Ÿæˆç¬‘è¯çš„é¢˜ç›®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45010efd-ad31-4daa-b77e-aaec79ef0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5296bb0-c163-4e5c-8181-1e305b37442a",
   "metadata": {},
   "source": [
    "è¿™é‡Œæ˜¯å…³é”®ï¼šæˆ‘ä»¬ä½¿ç”¨ [Send](https://langchain-ai.github.io/langgraph/concepts/low_level/#send) ä¸ºæ¯ä¸ªé¢˜ç›®ç”Ÿæˆç¬‘è¯ã€‚\n",
    "\n",
    "è¿™éå¸¸å®ç”¨ï¼å®ƒå¯ä»¥è‡ªåŠ¨å¹¶è¡Œåœ°ä¸ºä»»æ„æ•°é‡çš„é¢˜ç›®ç”Ÿæˆç¬‘è¯ã€‚\n",
    "\n",
    "* `generate_joke`ï¼šå›¾ä¸­èŠ‚ç‚¹çš„åç§°\n",
    "* `{\"subject\": s}`ï¼šè¦å‘é€çš„çŠ¶æ€\n",
    "\n",
    "`Send` å…è®¸ä½ æŠŠä»»æ„çŠ¶æ€ä¼ ç»™ `generate_joke`ï¼å®ƒä¸å¿…ä¸ `OverallState` å®Œå…¨ä¸€è‡´ã€‚\n",
    "\n",
    "åœ¨è¿™ä¸ªä¾‹å­é‡Œï¼Œ`generate_joke` ä½¿ç”¨å®ƒè‡ªå·±çš„å†…éƒ¨çŠ¶æ€ï¼Œæˆ‘ä»¬é€šè¿‡ `Send` æ¥å¡«å……å®ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc83e575-11f6-41a9-990a-adb571bcda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847192d-d358-411e-90c0-f06be0738717",
   "metadata": {},
   "source": [
    "### ç¬‘è¯ç”Ÿæˆï¼ˆmapï¼‰\n",
    "\n",
    "ç°åœ¨å®šä¹‰è´Ÿè´£åˆ›å»ºç¬‘è¯çš„èŠ‚ç‚¹ `generate_joke`ï¼\n",
    "\n",
    "æˆ‘ä»¬ä¼šæŠŠç¬‘è¯å†™å› `OverallState` ä¸­çš„ `jokes` é”®ã€‚\n",
    "\n",
    "è¿™ä¸ªé”®è®¾ç½®äº† reducerï¼Œç”¨æ¥åˆå¹¶åˆ—è¡¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcddc567-73d3-4fb3-bfc5-1bea538f2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02960657-d174-4076-99a8-b3f9eea015f4",
   "metadata": {},
   "source": [
    "### æœ€ä½³ç¬‘è¯é€‰æ‹©ï¼ˆreduceï¼‰\n",
    "\n",
    "æ¥ä¸‹æ¥æ·»åŠ é€»è¾‘ï¼Œé€‰å‡ºæœ€å¥½ç¬‘çš„ç¬‘è¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d672870-75e3-4307-bda0-c41a86cbbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd12e-5bff-426e-97f4-c774df998cfb",
   "metadata": {},
   "source": [
    "## ç¼–è¯‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae6be4b-144e-483c-88ad-ce86d6477a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "# Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e21dc7c9-0add-4125-be76-af701adb874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['Mammals', 'Reptiles', 'Birds']}}\n",
      "{'generate_joke': {'jokes': [\"Why don't birds use Facebook? Because they already have Twitter!\"]}}\n",
      "{'generate_joke': {'jokes': [\"Why don't mammals ever get lost? Because they always follow their 'paws'itive' instincts!\"]}}\n",
      "{'generate_joke': {'jokes': [\"Why don't reptiles ever get invited to card games? Because they always bring the scales!\"]}}\n",
      "{'best_joke': {'best_selected_joke': \"Why don't birds use Facebook? Because they already have Twitter!\"}}\n"
     ]
    }
   ],
   "source": [
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in app.stream({\"topic\": \"animals\"}):\n",
    "    print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a96517e-77ab-46e2-95e2-79168c044e9c",
   "metadata": {},
   "source": [
    "## Studio\n",
    "\n",
    "**âš ï¸ å…è´£å£°æ˜**\n",
    "\n",
    "è‡ªä»å½•åˆ¶è¿™äº›è§†é¢‘ä»¥æ¥ï¼Œæˆ‘ä»¬å·²ç»æ›´æ–°äº† Studioï¼Œä½¿å…¶å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ã€‚ç°åœ¨æ¨èçš„æ–¹å¼æ˜¯ä»¥è¿™ç§å½¢å¼è¿è¡Œ Studioï¼ˆè€Œä¸æ˜¯è§†é¢‘ä¸­å±•ç¤ºçš„æ¡Œé¢åº”ç”¨ï¼‰ã€‚å…³äºæœ¬åœ°å¼€å‘æœåŠ¡å™¨è¯·æŸ¥çœ‹[è¿™é‡Œ](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server)çš„æ–‡æ¡£ï¼Œå…³äºæœ¬åœ° Studio çš„è¿è¡Œæ–¹å¼è¯·æŸ¥çœ‹[è¿™é‡Œ](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server)ã€‚åœ¨æœ¬æ¨¡å—çš„ `/studio` ç›®å½•ä¸­ï¼Œåœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¯åŠ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨ï¼š\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "ä½ åº”è¯¥ä¼šçœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š\n",
    "```\n",
    "- ğŸš€ API: http://127.0.0.1:2024\n",
    "- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ğŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "åœ¨æµè§ˆå™¨ä¸­è®¿é—® Studio UIï¼š`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬åœ¨ Studio UI ä¸­åŠ è½½ä¸Šé¢çš„å›¾ï¼Œå®ƒç”± `module-4/studio/map_reduce.py` å®šä¹‰ï¼Œå¹¶åœ¨ `module-4/studio/langgraph.json` ä¸­è¿›è¡Œäº†é…ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a5e45-9a4c-43b4-8393-9298b3dcda53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
