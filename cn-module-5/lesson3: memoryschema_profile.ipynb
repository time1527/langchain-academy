{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用档案模式的聊天机器人 \n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们介绍了 [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)，作为保存与检索长期记忆的方式。\n",
    "\n",
    "我们构建了一个同时具备 `短期记忆（线程内）` 与 `长期记忆（跨线程）` 的简单聊天机器人。\n",
    "\n",
    "它会在用户对话的[“热路径”](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories)里保存长期的[语义记忆](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)，即关于用户的事实。\n",
    "\n",
    "## 目标\n",
    "\n",
    "之前的机器人把记忆以字符串保存。但在实践中，我们往往希望记忆具备结构化信息。\n",
    " \n",
    "例如，记忆可以是[单个、持续更新的模式](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)。\n",
    " \n",
    "在这个示例中，我们希望它是一个用户档案。\n",
    " \n",
    "我们将扩展聊天机器人，把语义记忆保存到单一的[用户档案](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)中。\n",
    "\n",
    "同时，我们会介绍 [Trustcall](https://github.com/hinthornw/trustcall) 这个库，用来往该模式中写入新的信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义用户档案模式\n",
    "\n",
    "Python 支持多种[结构化数据](https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition)的表示方式，例如 TypedDict、字典、JSON 以及 [Pydantic](https://docs.pydantic.dev/latest/)。\n",
    "\n",
    "我们先用 TypedDict 来定义一个用户档案模式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "\n",
    "class UserProfile(TypedDict):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "\n",
    "    user_name: str  # The user's preferred name\n",
    "    interests: List[str]  # A list of the user's interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将模式写入存储\n",
    "\n",
    "[LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) 接受任意 Python 字典作为 `value`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypedDict instance\n",
    "user_profile: UserProfile = {\n",
    "    \"user_name\": \"Lance\",\n",
    "    \"interests\": [\"biking\", \"technology\", \"coffee\"],\n",
    "}\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用 [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) 方法，把 TypedDict 保存到存储中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memory\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = \"user_profile\"\n",
    "value = user_profile\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过 [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) 根据命名空间检索存储中的对象。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}, 'created_at': '2025-09-28T16:43:03.668902+00:00', 'updated_at': '2025-09-28T16:43:03.668908+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search\n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以使用 [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get) 通过命名空间和键获取特定对象。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用档案模式的聊天机器人\n",
    "\n",
    "现在我们已经知道如何指定记忆的模式并把它保存到存储中。\n",
    "\n",
    "那么如何生成符合该模式的记忆呢？\n",
    "\n",
    "在聊天机器人中，我们希望[从用户对话中生成记忆](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)。\n",
    "\n",
    "这就需要用到[结构化输出](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage)的概念。\n",
    "\n",
    "LangChain 的[聊天模型](https://python.langchain.com/docs/concepts/chat_models/)接口提供了 [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 方法，用来强制输出遵循某个模式。\n",
    "\n",
    "当我们需要确保输出符合某个模式时，这个方法非常实用，并且它会替我们解析结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们把刚才定义的 `UserProfile` 模式传给 `with_structured_output`。\n",
    "\n",
    "然后，我们用一组[消息](https://python.langchain.com/docs/concepts/messages/)调用聊天模型，就能得到符合模式的结构化输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['bike']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke(\n",
    "    [HumanMessage(\"My name is Lance, I like to bike.\")]\n",
    ")\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在把这些能力整合到聊天机器人里。\n",
    "\n",
    "这只需要对 `write_memory` 函数做少量调整。\n",
    "\n",
    "我们使用上面定义的 `model_with_structure`，生成符合模式的档案。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "# used in  `call_model`\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "# used in `write_memory`\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = model_with_structure.invoke(\n",
    "        [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It’s great to meet you. San Francisco has some amazing spots for both biking and bakeries—have you got a favorite route or pastry shop yet? I’d love to hear about your adventures! 🚴‍♂️🥐\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来看一下存储中的记忆。\n",
    "\n",
    "可以看到这条记忆是一个与模式一致的字典。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'bakeries']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在什么情况下会失败？\n",
    "\n",
    "[`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 很有用，但如果模式更复杂会怎样呢？\n",
    "\n",
    "这里有一个[更复杂的模式](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)，我们会在下文测试。\n",
    "\n",
    "它是一个描述用户沟通偏好与“信任跌倒”场景的 [Pydantic](https://docs.pydantic.dev/latest/) 模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    preference: str\n",
    "    sentence_preference_revealed: str\n",
    "\n",
    "\n",
    "class TelegramPreferences(BaseModel):\n",
    "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
    "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
    "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class MorseCode(BaseModel):\n",
    "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
    "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class Semaphore(BaseModel):\n",
    "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
    "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class TrustFallPreferences(BaseModel):\n",
    "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
    "    trust_level: Optional[List[OutputFormat]] = None\n",
    "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class CommunicationPreferences(BaseModel):\n",
    "    telegram: TelegramPreferences\n",
    "    morse_code: MorseCode\n",
    "    semaphore: Semaphore\n",
    "\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    communication_preferences: CommunicationPreferences\n",
    "    trust_fall_preferences: TrustFallPreferences\n",
    "\n",
    "\n",
    "class TelegramAndTrustFallPreferences(BaseModel):\n",
    "    pertinent_user_preferences: UserPreferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们尝试用 `with_structured_output` 方法提取该模式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    model_with_structure.invoke(\n",
    "        f\"\"\"Extract the preferences from the following conversation:\n",
    "    <convo>\n",
    "    {conversation}\n",
    "    </convo>\"\"\"\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果直接提取复杂模式，即便使用像 `gpt-4o` 这种高能力模型，也很容易失败。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trustcall：创建与更新档案模式\n",
    "\n",
    "可见，处理模式并不轻松。\n",
    "\n",
    "复杂模式难以抽取。\n",
    "\n",
    "即便是简单模式，想要更新时也会遇到挑战。\n",
    "\n",
    "回想上面的聊天机器人。\n",
    "\n",
    "每次保存新记忆时，我们都需要从零生成整个档案模式。\n",
    "\n",
    "这既低效（如果模式信息很多会浪费大量 token），也可能导致信息丢失。\n",
    "\n",
    "解决上述问题正是 [TrustCall](https://github.com/hinthornw/trustcall) 的初心！\n",
    "\n",
    "它是 LangChain 团队的 [Will Fu-Hinthorn](https://github.com/hinthornw) 开源的 JSON 模式更新库。\n",
    "\n",
    "这些记忆相关的痛点直接促成了该工具。\n",
    "\n",
    "我们先对一个[消息列表](https://python.langchain.com/docs/concepts/messages/)演示 TrustCall 的基础抽取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Lance.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Lance.\"),\n",
    "    HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们调用 `create_extractor`，把模型和模式作为[工具](https://python.langchain.com/docs/concepts/tools/)传入。\n",
    "\n",
    "在 TrustCall 中，我们可以用多种方式提供模式。\n",
    "\n",
    "例如，直接传入 JSON 对象 / Python 字典或 Pydantic 模型。\n",
    "\n",
    "在底层，TrustCall 会使用[工具调用](https://python.langchain.com/docs/concepts/tool_calling/)从输入的[消息](https://python.langchain.com/docs/concepts/messages/)中产出[结构化输出](https://python.langchain.com/docs/concepts/structured_outputs/)。\n",
    "\n",
    "如果想强制 TrustCall 产生[结构化输出](https://python.langchain.com/docs/concepts/structured_outputs/)，可以在 `tool_choice` 参数中指明模式名称。\n",
    "\n",
    "随后，我们对上述对话调用抽取器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "\n",
    "# Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    interests: List[str] = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "# trustcall_extractor = create_extractor(\n",
    "#     model, tools=[UserProfile], tool_choice=\"UserProfile\"\n",
    "# )\n",
    "trustcall_extractor = create_extractor(model, tools=[UserProfile], tool_choice=\"auto\")\n",
    "\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\"messages\": [SystemMessage(content=system_msg)] + conversation}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用抽取器后，我们会得到：\n",
    "\n",
    "* `messages`：包含工具调用的 `AIMessage` 列表\n",
    "* `responses`：已经解析、符合模式的工具调用结果\n",
    "* `response_metadata`：当更新已有工具调用时会用到，告知每个返回结果对应的原对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_e77f4e6a791b453c8cc4a2)\n",
      " Call ID: call_e77f4e6a791b453c8cc4a2\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking around San Francisco']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='Lance', interests=['biking around San Francisco'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result[\"responses\"]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking around San Francisco']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_e77f4e6a791b453c8cc4a2'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来看看 TrustCall 如何用于*更新*档案。\n",
    "\n",
    "在更新场景下，TrustCall 会接收一组消息和现有的模式。\n",
    "\n",
    "核心想法是让模型只生成一个 [JSON Patch](https://jsonpatch.com/)，从而只更新相关部分。\n",
    "\n",
    "相比于直接重写整个模式，这种方式更不易出错。\n",
    "\n",
    "同时也更高效，因为模型只需生成发生变化的片段。\n",
    "\n",
    "我们可以先把现有模式保存成字典。\n",
    "\n",
    "通过 `model_dump()` 可以把 Pydantic 实例序列化为字典。\n",
    "\n",
    "然后，我们把它和模式名称 `UserProfile` 一起传入 `\"existing\"` 参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Lance.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Lance.\"),\n",
    "    HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
    "    AIMessage(content=\"San Francisco is a great city! Where do you go after biking?\"),\n",
    "    HumanMessage(content=\"I really like to go to a bakery after biking.\"),\n",
    "]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\"messages\": [SystemMessage(content=system_msg)] + updated_conversation},\n",
    "    {\"existing\": {\"UserProfile\": schema[0].model_dump()}},  # 与上面的不同之处\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_fdd36146d35a4c15b591bd)\n",
      " Call ID: call_fdd36146d35a4c15b591bd\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking', 'bakeries']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_fdd36146d35a4c15b591bd'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'bakeries']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_schema = result[\"responses\"][0]\n",
    "updated_schema.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith 追踪：\n",
    "\n",
    "https://smith.langchain.com/public/229eae22-1edb-44c6-93e6-489124a43968/r\n",
    "\n",
    "接着，我们也来测试一下上面那个[复杂模式](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 validation errors for TelegramAndTrustFallPreferences\n",
      "pertinent_user_preferences.communication_preferences.telegram\n",
      "  Input should be a valid dictionary or instance of TelegramPreferences [type=model_type, input_value=True, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.communication_preferences.morse_code\n",
      "  Input should be a valid dictionary or instance of MorseCode [type=model_type, input_value=True, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.communication_preferences.semaphore\n",
      "  Input should be a valid dictionary or instance of Semaphore [type=model_type, input_value=False, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.trust_fall_preferences.preferred_fall_height.0\n",
      "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='higher', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.trust_fall_preferences.preferred_catching_technique.0\n",
      "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='diamond formation', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
     ]
    }
   ],
   "source": [
    "bound = create_extractor(\n",
    "    model,\n",
    "    tools=[TelegramAndTrustFallPreferences],\n",
    "    # tool_choice=\"TelegramAndTrustFallPreferences\",\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "result = bound.invoke(\n",
    "    f\"\"\"Extract the preferences from the following conversation:\n",
    "<convo>\n",
    "{conversation}\n",
    "</convo>\"\"\"\n",
    ")\n",
    "\n",
    "# # Extract the preferences\n",
    "# result[\"responses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_98f3bd8edcd74d5eb1e2ad', 'type': 'function', 'function': {'name': 'TelegramAndTrustFallPreferences', 'arguments': '{\"pertinent_user_preferences\": {\"communication_preferences\": {\"telegram\": true, \"morse_code\": true, \"semaphore\": false}, \"trust_fall_preferences\": {\"preferred_fall_height\": [\"higher\"], \"preferred_catching_technique\": [\"diamond formation\"], \"trust_level\": null}, \"output_format\": {\"preference\": \"structured\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}}}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '78193993-9705-4887-911d-1d0e518a066f', 'token_usage': {'input_tokens': 1369, 'output_tokens': 117, 'total_tokens': 1486, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--098a1be5-35a0-49f9-8f84-ddc449f7065e-0', tool_calls=[{'name': 'TelegramAndTrustFallPreferences', 'args': {'pertinent_user_preferences': {'communication_preferences': {'telegram': True, 'morse_code': True, 'semaphore': False}, 'trust_fall_preferences': {'preferred_fall_height': ['higher'], 'preferred_catching_technique': ['diamond formation'], 'trust_level': None}, 'output_format': {'preference': 'structured', 'sentence_preference_revealed': \"Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\"}}}, 'id': 'call_98f3bd8edcd74d5eb1e2ad', 'type': 'tool_call'}])],\n",
       " 'responses': [],\n",
       " 'response_metadata': [],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追踪：\n",
    "\n",
    "https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r\n",
    "\n",
    "更多示例可以观看[这段总览视频](https://www.youtube.com/watch?v=-H4s0jQi-QY)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以更新档案模式的聊天机器人\n",
    "\n",
    "现在，我们把 TrustCall 引入聊天机器人，实现记忆档案的创建与更新。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "\n",
    "# Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"Profile of a user\"\"\"\n",
    "\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    user_location: str = Field(description=\"The user's location\")\n",
    "    interests: list = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    # tool_choice=\"UserProfile\",  # Enforces use of the UserProfile tool\n",
    "    # tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Extraction instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
    "    existing_profile = (\n",
    "        {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
    "    )\n",
    "    print(existing_profile)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    ###################### new #####################\n",
    "    # result = trustcall_extractor.invoke(\n",
    "    #     {\n",
    "    #         \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]\n",
    "    #         + state[\"messages\"],\n",
    "    #         \"existing\": existing_profile,\n",
    "    #     }\n",
    "    # )\n",
    "    result = trustcall_extractor.invoke(\n",
    "        {\n",
    "            \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]\n",
    "            + state[\"messages\"]\n",
    "        },\n",
    "        {\n",
    "            \"existing\": existing_profile,\n",
    "        },\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result[\"responses\"][0].model_dump()\n",
    "    ###################### new #####################\n",
    "\n",
    "    # Save the updated profile\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, updated_profile)\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you. How can I assist you today?\n",
      "None\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_e4bd9081841440f0a806d1', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"\", \"interests\": []}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'e3d3d713-ee52-4386-ba4b-99a15a7f8bdd', 'token_usage': {'input_tokens': 283, 'output_tokens': 31, 'total_tokens': 314, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--bdf9af92-42aa-4d5b-9084-6a55dc03c641-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': '', 'interests': []}, 'id': 'call_e4bd9081841440f0a806d1', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='', interests=[])], 'response_metadata': [{'id': 'call_e4bd9081841440f0a806d1'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hey Lance! That’s awesome—San Francisco has some incredible biking routes with amazing views. Whether you're cruising across the Golden Gate Bridge, riding through Golden Gate Park, or tackling the hills downtown (which I’ve got to assume means you’re in great shape!), there’s so much to explore. Do you have a favorite route or time of day to ride? 🚴‍♂️🌉\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': '', 'interests': []}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_e893a928fc1648db9104ae', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '27d9c71e-bb60-4b85-8492-b7b5001b7484', 'token_usage': {'input_tokens': 381, 'output_tokens': 37, 'total_tokens': 418, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--ce4a0431-dcc7-489a-b921-57c6e1903a75-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking']}, 'id': 'call_e893a928fc1648db9104ae', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking'])], 'response_metadata': [{'id': 'call_e893a928fc1648db9104ae'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Lance',\n",
       "  'user_location': 'San Francisco',\n",
       "  'interests': ['biking']},\n",
       " 'created_at': '2025-09-28T16:43:45.014569+00:00',\n",
       " 'updated_at': '2025-09-28T16:43:45.014572+00:00'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance',\n",
       " 'user_location': 'San Francisco',\n",
       " 'interests': ['biking']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The user profile saved as a JSON object\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That’s the perfect pairing, Lance—biking around San Francisco and rewarding yourself with a fresh pastry from one of the city’s amazing bakeries! After a ride through the Presidio or up Twin Peaks, there’s nothing better than stopping at a cozy spot for a warm croissant or a slice of sourdough. \n",
      "\n",
      "Have you been to **Tartine** in the Mission? It’s a biker favorite—great coffee, legendary morning buns. Or **Arsicault Bakery** in the Richmond? Their kouign-amann is basically a carb masterpiece. If you're biking near North Beach, **Sister’s Bakehouse** has that old-school charm and killer almond croissants.\n",
      "\n",
      "Want me to map out a sweet (literally) bakery bike route sometime? 🥐🚴‍♂️\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking']}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_9385c4e2db3945468cfa57', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\", \"bakeries\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'e3c79d66-d7a7-4536-8fe0-711878121669', 'token_usage': {'input_tokens': 567, 'output_tokens': 42, 'total_tokens': 609, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--d2fcdd49-cab0-4b06-aa59-dbf2d2378e09-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'bakeries']}, 'id': 'call_9385c4e2db3945468cfa57', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking', 'bakeries'])], 'response_metadata': [{'id': 'call_9385c4e2db3945468cfa57'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在新线程中继续对话。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hey Lance! Since you're in San Francisco and love biking, I’ve got some great bakery recommendations that are not only delicious but also fun to ride to. Here are a few local favorites:\n",
      "\n",
      "1. **Tartine Bakery (Mission District)** – A must-visit. Their morning buns and country bread are legendary. It’s a short, scenic bike ride from most parts of the city, and there’s often outdoor seating where you can enjoy your treat post-ride.\n",
      "\n",
      "2. **B. Patisserie (Nob Hill/CVille)** – Famous for their kouign-amann and beautiful viennoiserie. The croissants here are flaky perfection. It’s a bit hilly getting there, but totally worth it for the views and pastries.\n",
      "\n",
      "3. **Arsicault Bakery (Sunset & Arguello)** – Voted one of the best croissant spots in the U.S. The buttery, airy croissants are unreal. A longer ride if you’re coming from downtown, but a perfect destination after cruising through Golden Gate Park.\n",
      "\n",
      "4. **Jane the Bakery (North Beach)** – Great sourdough and sweet treats with a cozy vibe. Super accessible by bike along the Embarcadero, and close to Washington Square Park for a pastry picnic.\n",
      "\n",
      "5. **Seyfarth Bakery (Mission/Bernal Heights)** – A quieter gem with excellent seasonal pastries and bread. It’s nestled near Bernal Hill, so you can combine your visit with a nice climb and panoramic view.\n",
      "\n",
      "Want me to map out a “bakery bike tour” route for a weekend adventure? 🚴‍♂️🥐\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'bakeries']}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5900e782f56d4b7990e6cd', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\", \"pastries\", \"bakery hopping\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '6e663701-904f-4e17-82e2-04674b76769b', 'token_usage': {'input_tokens': 611, 'output_tokens': 46, 'total_tokens': 657, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--f6a94e92-7748-44a0-8ef2-fb61d06f2983-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'pastries', 'bakery hopping']}, 'id': 'call_5900e782f56d4b7990e6cd', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking', 'pastries', 'bakery hopping'])], 'response_metadata': [{'id': 'call_5900e782f56d4b7990e6cd'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追踪：\n",
    "\n",
    "https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r\n",
    "\n",
    "## Studio\n",
    "\n",
    "![Screenshot 2024-10-30 at 11.26.31 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0437060f1754ea79908_Screenshot%202024-11-11%20at%207.48.53%E2%80%AFPM.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
