{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨æ¡£æ¡ˆæ¨¡å¼çš„èŠå¤©æœºå™¨äºº \n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬ä»‹ç»äº† [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)ï¼Œä½œä¸ºä¿å­˜ä¸æ£€ç´¢é•¿æœŸè®°å¿†çš„æ–¹å¼ã€‚\n",
    "\n",
    "æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒæ—¶å…·å¤‡ `çŸ­æœŸè®°å¿†ï¼ˆçº¿ç¨‹å†…ï¼‰` ä¸ `é•¿æœŸè®°å¿†ï¼ˆè·¨çº¿ç¨‹ï¼‰` çš„ç®€å•èŠå¤©æœºå™¨äººã€‚\n",
    "\n",
    "å®ƒä¼šåœ¨ç”¨æˆ·å¯¹è¯çš„[â€œçƒ­è·¯å¾„â€](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories)é‡Œä¿å­˜é•¿æœŸçš„[è¯­ä¹‰è®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)ï¼Œå³å…³äºç”¨æˆ·çš„äº‹å®ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "ä¹‹å‰çš„æœºå™¨äººæŠŠè®°å¿†ä»¥å­—ç¬¦ä¸²ä¿å­˜ã€‚ä½†åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¾€å¾€å¸Œæœ›è®°å¿†å…·å¤‡ç»“æ„åŒ–ä¿¡æ¯ã€‚\n",
    " \n",
    "ä¾‹å¦‚ï¼Œè®°å¿†å¯ä»¥æ˜¯[å•ä¸ªã€æŒç»­æ›´æ–°çš„æ¨¡å¼](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)ã€‚\n",
    " \n",
    "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒæ˜¯ä¸€ä¸ªç”¨æˆ·æ¡£æ¡ˆã€‚\n",
    " \n",
    "æˆ‘ä»¬å°†æ‰©å±•èŠå¤©æœºå™¨äººï¼ŒæŠŠè¯­ä¹‰è®°å¿†ä¿å­˜åˆ°å•ä¸€çš„[ç”¨æˆ·æ¡£æ¡ˆ](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)ä¸­ã€‚\n",
    "\n",
    "åŒæ—¶ï¼Œæˆ‘ä»¬ä¼šä»‹ç» [Trustcall](https://github.com/hinthornw/trustcall) è¿™ä¸ªåº“ï¼Œç”¨æ¥å¾€è¯¥æ¨¡å¼ä¸­å†™å…¥æ–°çš„ä¿¡æ¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®šä¹‰ç”¨æˆ·æ¡£æ¡ˆæ¨¡å¼\n",
    "\n",
    "Python æ”¯æŒå¤šç§[ç»“æ„åŒ–æ•°æ®](https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition)çš„è¡¨ç¤ºæ–¹å¼ï¼Œä¾‹å¦‚ TypedDictã€å­—å…¸ã€JSON ä»¥åŠ [Pydantic](https://docs.pydantic.dev/latest/)ã€‚\n",
    "\n",
    "æˆ‘ä»¬å…ˆç”¨ TypedDict æ¥å®šä¹‰ä¸€ä¸ªç”¨æˆ·æ¡£æ¡ˆæ¨¡å¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "\n",
    "class UserProfile(TypedDict):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "\n",
    "    user_name: str  # The user's preferred name\n",
    "    interests: List[str]  # A list of the user's interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å°†æ¨¡å¼å†™å…¥å­˜å‚¨\n",
    "\n",
    "[LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) æ¥å—ä»»æ„ Python å­—å…¸ä½œä¸º `value`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypedDict instance\n",
    "user_profile: UserProfile = {\n",
    "    \"user_name\": \"Lance\",\n",
    "    \"interests\": [\"biking\", \"technology\", \"coffee\"],\n",
    "}\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä½¿ç”¨ [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) æ–¹æ³•ï¼ŒæŠŠ TypedDict ä¿å­˜åˆ°å­˜å‚¨ä¸­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memory\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = \"user_profile\"\n",
    "value = user_profile\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬é€šè¿‡ [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) æ ¹æ®å‘½åç©ºé—´æ£€ç´¢å­˜å‚¨ä¸­çš„å¯¹è±¡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}, 'created_at': '2025-09-28T16:43:03.668902+00:00', 'updated_at': '2025-09-28T16:43:03.668908+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search\n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get) é€šè¿‡å‘½åç©ºé—´å’Œé”®è·å–ç‰¹å®šå¯¹è±¡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨æ¡£æ¡ˆæ¨¡å¼çš„èŠå¤©æœºå™¨äºº\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»çŸ¥é“å¦‚ä½•æŒ‡å®šè®°å¿†çš„æ¨¡å¼å¹¶æŠŠå®ƒä¿å­˜åˆ°å­˜å‚¨ä¸­ã€‚\n",
    "\n",
    "é‚£ä¹ˆå¦‚ä½•ç”Ÿæˆç¬¦åˆè¯¥æ¨¡å¼çš„è®°å¿†å‘¢ï¼Ÿ\n",
    "\n",
    "åœ¨èŠå¤©æœºå™¨äººä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›[ä»ç”¨æˆ·å¯¹è¯ä¸­ç”Ÿæˆè®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)ã€‚\n",
    "\n",
    "è¿™å°±éœ€è¦ç”¨åˆ°[ç»“æ„åŒ–è¾“å‡º](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage)çš„æ¦‚å¿µã€‚\n",
    "\n",
    "LangChain çš„[èŠå¤©æ¨¡å‹](https://python.langchain.com/docs/concepts/chat_models/)æ¥å£æä¾›äº† [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) æ–¹æ³•ï¼Œç”¨æ¥å¼ºåˆ¶è¾“å‡ºéµå¾ªæŸä¸ªæ¨¡å¼ã€‚\n",
    "\n",
    "å½“æˆ‘ä»¬éœ€è¦ç¡®ä¿è¾“å‡ºç¬¦åˆæŸä¸ªæ¨¡å¼æ—¶ï¼Œè¿™ä¸ªæ–¹æ³•éå¸¸å®ç”¨ï¼Œå¹¶ä¸”å®ƒä¼šæ›¿æˆ‘ä»¬è§£æç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æŠŠåˆšæ‰å®šä¹‰çš„ `UserProfile` æ¨¡å¼ä¼ ç»™ `with_structured_output`ã€‚\n",
    "\n",
    "ç„¶åï¼Œæˆ‘ä»¬ç”¨ä¸€ç»„[æ¶ˆæ¯](https://python.langchain.com/docs/concepts/messages/)è°ƒç”¨èŠå¤©æ¨¡å‹ï¼Œå°±èƒ½å¾—åˆ°ç¬¦åˆæ¨¡å¼çš„ç»“æ„åŒ–è¾“å‡ºã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['bike']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke(\n",
    "    [HumanMessage(\"My name is Lance, I like to bike.\")]\n",
    ")\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æŠŠè¿™äº›èƒ½åŠ›æ•´åˆåˆ°èŠå¤©æœºå™¨äººé‡Œã€‚\n",
    "\n",
    "è¿™åªéœ€è¦å¯¹ `write_memory` å‡½æ•°åšå°‘é‡è°ƒæ•´ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ `model_with_structure`ï¼Œç”Ÿæˆç¬¦åˆæ¨¡å¼çš„æ¡£æ¡ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "# used in  `call_model`\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "# used in `write_memory`\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = model_with_structure.invoke(\n",
    "        [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Itâ€™s great to meet you. San Francisco has some amazing spots for both biking and bakeriesâ€”have you got a favorite route or pastry shop yet? Iâ€™d love to hear about your adventures! ğŸš´â€â™‚ï¸ğŸ¥\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Hi, my name is Lance and I like to bike around San Francisco and eat at bakeries.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥çœ‹ä¸€ä¸‹å­˜å‚¨ä¸­çš„è®°å¿†ã€‚\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°è¿™æ¡è®°å¿†æ˜¯ä¸€ä¸ªä¸æ¨¡å¼ä¸€è‡´çš„å­—å…¸ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'bakeries']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šå¤±è´¥ï¼Ÿ\n",
    "\n",
    "[`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) å¾ˆæœ‰ç”¨ï¼Œä½†å¦‚æœæ¨¡å¼æ›´å¤æ‚ä¼šæ€æ ·å‘¢ï¼Ÿ\n",
    "\n",
    "è¿™é‡Œæœ‰ä¸€ä¸ª[æ›´å¤æ‚çš„æ¨¡å¼](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)ï¼Œæˆ‘ä»¬ä¼šåœ¨ä¸‹æ–‡æµ‹è¯•ã€‚\n",
    "\n",
    "å®ƒæ˜¯ä¸€ä¸ªæè¿°ç”¨æˆ·æ²Ÿé€šåå¥½ä¸â€œä¿¡ä»»è·Œå€’â€åœºæ™¯çš„ [Pydantic](https://docs.pydantic.dev/latest/) æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    preference: str\n",
    "    sentence_preference_revealed: str\n",
    "\n",
    "\n",
    "class TelegramPreferences(BaseModel):\n",
    "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
    "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
    "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class MorseCode(BaseModel):\n",
    "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
    "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class Semaphore(BaseModel):\n",
    "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
    "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class TrustFallPreferences(BaseModel):\n",
    "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
    "    trust_level: Optional[List[OutputFormat]] = None\n",
    "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
    "\n",
    "\n",
    "class CommunicationPreferences(BaseModel):\n",
    "    telegram: TelegramPreferences\n",
    "    morse_code: MorseCode\n",
    "    semaphore: Semaphore\n",
    "\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    communication_preferences: CommunicationPreferences\n",
    "    trust_fall_preferences: TrustFallPreferences\n",
    "\n",
    "\n",
    "class TelegramAndTrustFallPreferences(BaseModel):\n",
    "    pertinent_user_preferences: UserPreferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°è¯•ç”¨ `with_structured_output` æ–¹æ³•æå–è¯¥æ¨¡å¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    model_with_structure.invoke(\n",
    "        f\"\"\"Extract the preferences from the following conversation:\n",
    "    <convo>\n",
    "    {conversation}\n",
    "    </convo>\"\"\"\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœç›´æ¥æå–å¤æ‚æ¨¡å¼ï¼Œå³ä¾¿ä½¿ç”¨åƒ `gpt-4o` è¿™ç§é«˜èƒ½åŠ›æ¨¡å‹ï¼Œä¹Ÿå¾ˆå®¹æ˜“å¤±è´¥ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trustcallï¼šåˆ›å»ºä¸æ›´æ–°æ¡£æ¡ˆæ¨¡å¼\n",
    "\n",
    "å¯è§ï¼Œå¤„ç†æ¨¡å¼å¹¶ä¸è½»æ¾ã€‚\n",
    "\n",
    "å¤æ‚æ¨¡å¼éš¾ä»¥æŠ½å–ã€‚\n",
    "\n",
    "å³ä¾¿æ˜¯ç®€å•æ¨¡å¼ï¼Œæƒ³è¦æ›´æ–°æ—¶ä¹Ÿä¼šé‡åˆ°æŒ‘æˆ˜ã€‚\n",
    "\n",
    "å›æƒ³ä¸Šé¢çš„èŠå¤©æœºå™¨äººã€‚\n",
    "\n",
    "æ¯æ¬¡ä¿å­˜æ–°è®°å¿†æ—¶ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ä»é›¶ç”Ÿæˆæ•´ä¸ªæ¡£æ¡ˆæ¨¡å¼ã€‚\n",
    "\n",
    "è¿™æ—¢ä½æ•ˆï¼ˆå¦‚æœæ¨¡å¼ä¿¡æ¯å¾ˆå¤šä¼šæµªè´¹å¤§é‡ tokenï¼‰ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ã€‚\n",
    "\n",
    "è§£å†³ä¸Šè¿°é—®é¢˜æ­£æ˜¯ [TrustCall](https://github.com/hinthornw/trustcall) çš„åˆå¿ƒï¼\n",
    "\n",
    "å®ƒæ˜¯ LangChain å›¢é˜Ÿçš„ [Will Fu-Hinthorn](https://github.com/hinthornw) å¼€æºçš„ JSON æ¨¡å¼æ›´æ–°åº“ã€‚\n",
    "\n",
    "è¿™äº›è®°å¿†ç›¸å…³çš„ç—›ç‚¹ç›´æ¥ä¿ƒæˆäº†è¯¥å·¥å…·ã€‚\n",
    "\n",
    "æˆ‘ä»¬å…ˆå¯¹ä¸€ä¸ª[æ¶ˆæ¯åˆ—è¡¨](https://python.langchain.com/docs/concepts/messages/)æ¼”ç¤º TrustCall çš„åŸºç¡€æŠ½å–ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Lance.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Lance.\"),\n",
    "    HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬è°ƒç”¨ `create_extractor`ï¼ŒæŠŠæ¨¡å‹å’Œæ¨¡å¼ä½œä¸º[å·¥å…·](https://python.langchain.com/docs/concepts/tools/)ä¼ å…¥ã€‚\n",
    "\n",
    "åœ¨ TrustCall ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å¤šç§æ–¹å¼æä¾›æ¨¡å¼ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œç›´æ¥ä¼ å…¥ JSON å¯¹è±¡ / Python å­—å…¸æˆ– Pydantic æ¨¡å‹ã€‚\n",
    "\n",
    "åœ¨åº•å±‚ï¼ŒTrustCall ä¼šä½¿ç”¨[å·¥å…·è°ƒç”¨](https://python.langchain.com/docs/concepts/tool_calling/)ä»è¾“å…¥çš„[æ¶ˆæ¯](https://python.langchain.com/docs/concepts/messages/)ä¸­äº§å‡º[ç»“æ„åŒ–è¾“å‡º](https://python.langchain.com/docs/concepts/structured_outputs/)ã€‚\n",
    "\n",
    "å¦‚æœæƒ³å¼ºåˆ¶ TrustCall äº§ç”Ÿ[ç»“æ„åŒ–è¾“å‡º](https://python.langchain.com/docs/concepts/structured_outputs/)ï¼Œå¯ä»¥åœ¨ `tool_choice` å‚æ•°ä¸­æŒ‡æ˜æ¨¡å¼åç§°ã€‚\n",
    "\n",
    "éšåï¼Œæˆ‘ä»¬å¯¹ä¸Šè¿°å¯¹è¯è°ƒç”¨æŠ½å–å™¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "\n",
    "# Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    interests: List[str] = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "# trustcall_extractor = create_extractor(\n",
    "#     model, tools=[UserProfile], tool_choice=\"UserProfile\"\n",
    "# )\n",
    "trustcall_extractor = create_extractor(model, tools=[UserProfile], tool_choice=\"auto\")\n",
    "\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\"messages\": [SystemMessage(content=system_msg)] + conversation}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨æŠ½å–å™¨åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ï¼š\n",
    "\n",
    "* `messages`ï¼šåŒ…å«å·¥å…·è°ƒç”¨çš„ `AIMessage` åˆ—è¡¨\n",
    "* `responses`ï¼šå·²ç»è§£æã€ç¬¦åˆæ¨¡å¼çš„å·¥å…·è°ƒç”¨ç»“æœ\n",
    "* `response_metadata`ï¼šå½“æ›´æ–°å·²æœ‰å·¥å…·è°ƒç”¨æ—¶ä¼šç”¨åˆ°ï¼Œå‘ŠçŸ¥æ¯ä¸ªè¿”å›ç»“æœå¯¹åº”çš„åŸå¯¹è±¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_e77f4e6a791b453c8cc4a2)\n",
      " Call ID: call_e77f4e6a791b453c8cc4a2\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking around San Francisco']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='Lance', interests=['biking around San Francisco'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result[\"responses\"]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking around San Francisco']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_e77f4e6a791b453c8cc4a2'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥çœ‹çœ‹ TrustCall å¦‚ä½•ç”¨äº*æ›´æ–°*æ¡£æ¡ˆã€‚\n",
    "\n",
    "åœ¨æ›´æ–°åœºæ™¯ä¸‹ï¼ŒTrustCall ä¼šæ¥æ”¶ä¸€ç»„æ¶ˆæ¯å’Œç°æœ‰çš„æ¨¡å¼ã€‚\n",
    "\n",
    "æ ¸å¿ƒæƒ³æ³•æ˜¯è®©æ¨¡å‹åªç”Ÿæˆä¸€ä¸ª [JSON Patch](https://jsonpatch.com/)ï¼Œä»è€Œåªæ›´æ–°ç›¸å…³éƒ¨åˆ†ã€‚\n",
    "\n",
    "ç›¸æ¯”äºç›´æ¥é‡å†™æ•´ä¸ªæ¨¡å¼ï¼Œè¿™ç§æ–¹å¼æ›´ä¸æ˜“å‡ºé”™ã€‚\n",
    "\n",
    "åŒæ—¶ä¹Ÿæ›´é«˜æ•ˆï¼Œå› ä¸ºæ¨¡å‹åªéœ€ç”Ÿæˆå‘ç”Ÿå˜åŒ–çš„ç‰‡æ®µã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥å…ˆæŠŠç°æœ‰æ¨¡å¼ä¿å­˜æˆå­—å…¸ã€‚\n",
    "\n",
    "é€šè¿‡ `model_dump()` å¯ä»¥æŠŠ Pydantic å®ä¾‹åºåˆ—åŒ–ä¸ºå­—å…¸ã€‚\n",
    "\n",
    "ç„¶åï¼Œæˆ‘ä»¬æŠŠå®ƒå’Œæ¨¡å¼åç§° `UserProfile` ä¸€èµ·ä¼ å…¥ `\"existing\"` å‚æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Lance.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Lance.\"),\n",
    "    HumanMessage(content=\"I really like biking around San Francisco.\"),\n",
    "    AIMessage(content=\"San Francisco is a great city! Where do you go after biking?\"),\n",
    "    HumanMessage(content=\"I really like to go to a bakery after biking.\"),\n",
    "]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\"messages\": [SystemMessage(content=system_msg)] + updated_conversation},\n",
    "    {\"existing\": {\"UserProfile\": schema[0].model_dump()}},  # ä¸ä¸Šé¢çš„ä¸åŒä¹‹å¤„\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_fdd36146d35a4c15b591bd)\n",
      " Call ID: call_fdd36146d35a4c15b591bd\n",
      "  Args:\n",
      "    user_name: Lance\n",
      "    interests: ['biking', 'bakeries']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_fdd36146d35a4c15b591bd'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance', 'interests': ['biking', 'bakeries']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_schema = result[\"responses\"][0]\n",
    "updated_schema.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith è¿½è¸ªï¼š\n",
    "\n",
    "https://smith.langchain.com/public/229eae22-1edb-44c6-93e6-489124a43968/r\n",
    "\n",
    "æ¥ç€ï¼Œæˆ‘ä»¬ä¹Ÿæ¥æµ‹è¯•ä¸€ä¸‹ä¸Šé¢é‚£ä¸ª[å¤æ‚æ¨¡å¼](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 validation errors for TelegramAndTrustFallPreferences\n",
      "pertinent_user_preferences.communication_preferences.telegram\n",
      "  Input should be a valid dictionary or instance of TelegramPreferences [type=model_type, input_value=True, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.communication_preferences.morse_code\n",
      "  Input should be a valid dictionary or instance of MorseCode [type=model_type, input_value=True, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.communication_preferences.semaphore\n",
      "  Input should be a valid dictionary or instance of Semaphore [type=model_type, input_value=False, input_type=bool]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.trust_fall_preferences.preferred_fall_height.0\n",
      "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='higher', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n",
      "pertinent_user_preferences.trust_fall_preferences.preferred_catching_technique.0\n",
      "  Input should be a valid dictionary or instance of OutputFormat [type=model_type, input_value='diamond formation', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
     ]
    }
   ],
   "source": [
    "bound = create_extractor(\n",
    "    model,\n",
    "    tools=[TelegramAndTrustFallPreferences],\n",
    "    # tool_choice=\"TelegramAndTrustFallPreferences\",\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "result = bound.invoke(\n",
    "    f\"\"\"Extract the preferences from the following conversation:\n",
    "<convo>\n",
    "{conversation}\n",
    "</convo>\"\"\"\n",
    ")\n",
    "\n",
    "# # Extract the preferences\n",
    "# result[\"responses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_98f3bd8edcd74d5eb1e2ad', 'type': 'function', 'function': {'name': 'TelegramAndTrustFallPreferences', 'arguments': '{\"pertinent_user_preferences\": {\"communication_preferences\": {\"telegram\": true, \"morse_code\": true, \"semaphore\": false}, \"trust_fall_preferences\": {\"preferred_fall_height\": [\"higher\"], \"preferred_catching_technique\": [\"diamond formation\"], \"trust_level\": null}, \"output_format\": {\"preference\": \"structured\", \"sentence_preference_revealed\": \"Tell him I\\'m ready for a higher fall, and I prefer the diamond formation for catching.\"}}}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '78193993-9705-4887-911d-1d0e518a066f', 'token_usage': {'input_tokens': 1369, 'output_tokens': 117, 'total_tokens': 1486, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--098a1be5-35a0-49f9-8f84-ddc449f7065e-0', tool_calls=[{'name': 'TelegramAndTrustFallPreferences', 'args': {'pertinent_user_preferences': {'communication_preferences': {'telegram': True, 'morse_code': True, 'semaphore': False}, 'trust_fall_preferences': {'preferred_fall_height': ['higher'], 'preferred_catching_technique': ['diamond formation'], 'trust_level': None}, 'output_format': {'preference': 'structured', 'sentence_preference_revealed': \"Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\"}}}, 'id': 'call_98f3bd8edcd74d5eb1e2ad', 'type': 'tool_call'}])],\n",
       " 'responses': [],\n",
       " 'response_metadata': [],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿½è¸ªï¼š\n",
    "\n",
    "https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r\n",
    "\n",
    "æ›´å¤šç¤ºä¾‹å¯ä»¥è§‚çœ‹[è¿™æ®µæ€»è§ˆè§†é¢‘](https://www.youtube.com/watch?v=-H4s0jQi-QY)ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯ä»¥æ›´æ–°æ¡£æ¡ˆæ¨¡å¼çš„èŠå¤©æœºå™¨äºº\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬æŠŠ TrustCall å¼•å…¥èŠå¤©æœºå™¨äººï¼Œå®ç°è®°å¿†æ¡£æ¡ˆçš„åˆ›å»ºä¸æ›´æ–°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "\n",
    "# Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"Profile of a user\"\"\"\n",
    "\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    user_location: str = Field(description=\"The user's location\")\n",
    "    interests: list = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    # tool_choice=\"UserProfile\",  # Enforces use of the UserProfile tool\n",
    "    # tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Extraction instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
    "    existing_profile = (\n",
    "        {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
    "    )\n",
    "    print(existing_profile)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    ###################### new #####################\n",
    "    # result = trustcall_extractor.invoke(\n",
    "    #     {\n",
    "    #         \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]\n",
    "    #         + state[\"messages\"],\n",
    "    #         \"existing\": existing_profile,\n",
    "    #     }\n",
    "    # )\n",
    "    result = trustcall_extractor.invoke(\n",
    "        {\n",
    "            \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]\n",
    "            + state[\"messages\"]\n",
    "        },\n",
    "        {\n",
    "            \"existing\": existing_profile,\n",
    "        },\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result[\"responses\"][0].model_dump()\n",
    "    ###################### new #####################\n",
    "\n",
    "    # Save the updated profile\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, updated_profile)\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you. How can I assist you today?\n",
      "None\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_e4bd9081841440f0a806d1', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"\", \"interests\": []}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'e3d3d713-ee52-4386-ba4b-99a15a7f8bdd', 'token_usage': {'input_tokens': 283, 'output_tokens': 31, 'total_tokens': 314, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--bdf9af92-42aa-4d5b-9084-6a55dc03c641-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': '', 'interests': []}, 'id': 'call_e4bd9081841440f0a806d1', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='', interests=[])], 'response_metadata': [{'id': 'call_e4bd9081841440f0a806d1'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hey Lance! Thatâ€™s awesomeâ€”San Francisco has some incredible biking routes with amazing views. Whether you're cruising across the Golden Gate Bridge, riding through Golden Gate Park, or tackling the hills downtown (which Iâ€™ve got to assume means youâ€™re in great shape!), thereâ€™s so much to explore. Do you have a favorite route or time of day to ride? ğŸš´â€â™‚ï¸ğŸŒ‰\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': '', 'interests': []}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_e893a928fc1648db9104ae', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '27d9c71e-bb60-4b85-8492-b7b5001b7484', 'token_usage': {'input_tokens': 381, 'output_tokens': 37, 'total_tokens': 418, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--ce4a0431-dcc7-489a-b921-57c6e1903a75-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking']}, 'id': 'call_e893a928fc1648db9104ae', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking'])], 'response_metadata': [{'id': 'call_e893a928fc1648db9104ae'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Lance',\n",
       "  'user_location': 'San Francisco',\n",
       "  'interests': ['biking']},\n",
       " 'created_at': '2025-09-28T16:43:45.014569+00:00',\n",
       " 'updated_at': '2025-09-28T16:43:45.014572+00:00'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Lance',\n",
       " 'user_location': 'San Francisco',\n",
       " 'interests': ['biking']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The user profile saved as a JSON object\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thatâ€™s the perfect pairing, Lanceâ€”biking around San Francisco and rewarding yourself with a fresh pastry from one of the cityâ€™s amazing bakeries! After a ride through the Presidio or up Twin Peaks, thereâ€™s nothing better than stopping at a cozy spot for a warm croissant or a slice of sourdough. \n",
      "\n",
      "Have you been to **Tartine** in the Mission? Itâ€™s a biker favoriteâ€”great coffee, legendary morning buns. Or **Arsicault Bakery** in the Richmond? Their kouign-amann is basically a carb masterpiece. If you're biking near North Beach, **Sisterâ€™s Bakehouse** has that old-school charm and killer almond croissants.\n",
      "\n",
      "Want me to map out a sweet (literally) bakery bike route sometime? ğŸ¥ğŸš´â€â™‚ï¸\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking']}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_9385c4e2db3945468cfa57', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\", \"bakeries\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': 'e3c79d66-d7a7-4536-8fe0-711878121669', 'token_usage': {'input_tokens': 567, 'output_tokens': 42, 'total_tokens': 609, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--d2fcdd49-cab0-4b06-aa59-dbf2d2378e09-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'bakeries']}, 'id': 'call_9385c4e2db3945468cfa57', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking', 'bakeries'])], 'response_metadata': [{'id': 'call_9385c4e2db3945468cfa57'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æ–°çº¿ç¨‹ä¸­ç»§ç»­å¯¹è¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hey Lance! Since you're in San Francisco and love biking, Iâ€™ve got some great bakery recommendations that are not only delicious but also fun to ride to. Here are a few local favorites:\n",
      "\n",
      "1. **Tartine Bakery (Mission District)** â€“ A must-visit. Their morning buns and country bread are legendary. Itâ€™s a short, scenic bike ride from most parts of the city, and thereâ€™s often outdoor seating where you can enjoy your treat post-ride.\n",
      "\n",
      "2. **B. Patisserie (Nob Hill/CVille)** â€“ Famous for their kouign-amann and beautiful viennoiserie. The croissants here are flaky perfection. Itâ€™s a bit hilly getting there, but totally worth it for the views and pastries.\n",
      "\n",
      "3. **Arsicault Bakery (Sunset & Arguello)** â€“ Voted one of the best croissant spots in the U.S. The buttery, airy croissants are unreal. A longer ride if youâ€™re coming from downtown, but a perfect destination after cruising through Golden Gate Park.\n",
      "\n",
      "4. **Jane the Bakery (North Beach)** â€“ Great sourdough and sweet treats with a cozy vibe. Super accessible by bike along the Embarcadero, and close to Washington Square Park for a pastry picnic.\n",
      "\n",
      "5. **Seyfarth Bakery (Mission/Bernal Heights)** â€“ A quieter gem with excellent seasonal pastries and bread. Itâ€™s nestled near Bernal Hill, so you can combine your visit with a nice climb and panoramic view.\n",
      "\n",
      "Want me to map out a â€œbakery bike tourâ€ route for a weekend adventure? ğŸš´â€â™‚ï¸ğŸ¥\n",
      "{'UserProfile': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'bakeries']}}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5900e782f56d4b7990e6cd', 'type': 'function', 'function': {'name': 'UserProfile', 'arguments': '{\"user_name\": \"Lance\", \"user_location\": \"San Francisco\", \"interests\": [\"biking\", \"pastries\", \"bakery hopping\"]}'}}]}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'tool_calls', 'request_id': '6e663701-904f-4e17-82e2-04674b76769b', 'token_usage': {'input_tokens': 611, 'output_tokens': 46, 'total_tokens': 657, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--f6a94e92-7748-44a0-8ef2-fb61d06f2983-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Lance', 'user_location': 'San Francisco', 'interests': ['biking', 'pastries', 'bakery hopping']}, 'id': 'call_5900e782f56d4b7990e6cd', 'type': 'tool_call'}])], 'responses': [UserProfile(user_name='Lance', user_location='San Francisco', interests=['biking', 'pastries', 'bakery hopping'])], 'response_metadata': [{'id': 'call_5900e782f56d4b7990e6cd'}], 'attempts': 1}\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input\n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿½è¸ªï¼š\n",
    "\n",
    "https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r\n",
    "\n",
    "## Studio\n",
    "\n",
    "![Screenshot 2024-10-30 at 11.26.31 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0437060f1754ea79908_Screenshot%202024-11-11%20at%207.48.53%E2%80%AFPM.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
