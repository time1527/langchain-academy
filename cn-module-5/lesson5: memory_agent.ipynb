{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 记忆型智能体\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们构建了一个聊天机器人，把语义记忆保存到单一[用户档案](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)或[集合](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)中。\n",
    "\n",
    "我们引入了 [Trustcall](https://github.com/hinthornw/trustcall) 来更新这两类模式。\n",
    "\n",
    "## 目标\n",
    "\n",
    "现在，我们将整合前面学到的内容，构建一个具备长期记忆的[智能体](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)。\n",
    "\n",
    "这个智能体叫 `task_mAIstro`，用于帮我们管理 ToDo 清单！\n",
    "\n",
    "此前的聊天机器人会*自动*反思对话并保存记忆。\n",
    "\n",
    "`task_mAIstro` 会自行判断 *何时* 保存记忆（即 ToDo 项目）。\n",
    "\n",
    "此前的聊天机器人只会保存一种记忆：档案或者集合。\n",
    "\n",
    "`task_mAIstro` 可以决定把信息写入用户档案，或写入 ToDo 项目的集合。\n",
    "\n",
    "除了语义记忆，`task_mAIstro` 还会管理程序性记忆。\n",
    "\n",
    "这样用户就能更新它创建 ToDo 项目的偏好。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 了解 Trustcall 的更新细节\n",
    "\n",
    "Trustcall 负责创建与更新 JSON 模式。\n",
    "\n",
    "如果我们希望了解 Trustcall 做了哪些*具体改动*，该怎么办？\n",
    "\n",
    "例如，我们之前看到 Trustcall 自带的工具可以：\n",
    "\n",
    "* 出现校验失败时自我纠错 —— [示例追踪](https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r/9684db76-2003-443b-9aa2-9a9dbc5498b7)\n",
    "* 更新已有文档 —— [示例追踪](https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r/760f90e1-a5dc-48f1-8c34-79d6a3414ac3)\n",
    "\n",
    "了解这些工具的行为，对我们即将构建的智能体很有帮助。\n",
    "\n",
    "下面展示如何实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(\n",
    "        description=\"The main content of the memory. For example: User expressed interest in learning about French.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以给 Trustcall 抽取器添加一个[监听器](https://python.langchain.com/docs/how_to/lcel_cheatsheet/#add-lifecycle-listeners)。\n",
    "\n",
    "这样抽取器的运行信息就会传递给我们定义的 `Spy` 类。\n",
    "\n",
    "`Spy` 会提取 Trustcall 所触发的工具调用信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "\n",
    "# Inspect the tool calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "\n",
    "# Initialize the spy\n",
    "spy = Spy()\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen3-max\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    # tool_choice=\"Memory\",\n",
    "    tool_choice=\"auto\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Lance.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Lance.\"),\n",
    "    HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\"),\n",
    "]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke(\n",
    "    {\"messages\": [SystemMessage(content=instruction)] + conversation}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_f4c461236287499eba7e4634)\n",
      " Call ID: call_f4c461236287499eba7e4634\n",
      "  Args:\n",
      "    content: Lance had a nice bike ride in San Francisco this morning.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Lance had a nice bike ride in San Francisco this morning.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_f4c461236287499eba7e4634'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Lance had a nice bike ride in San Francisco this morning.'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [\n",
    "    AIMessage(content=\"That's great, did you do after?\"),\n",
    "    HumanMessage(content=\"I went to Tartine and ate a croissant.\"),\n",
    "    AIMessage(content=\"What else is on your mind?\"),\n",
    "    HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),\n",
    "]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = (\n",
    "    [\n",
    "        (str(i), tool_name, memory.model_dump())\n",
    "        for i, memory in enumerate(result[\"responses\"])\n",
    "    ]\n",
    "    if result[\"responses\"]\n",
    "    else None\n",
    ")\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke(\n",
    "    # {\"messages\": updated_conversation, \"existing\": existing_memories}\n",
    "    {\"messages\": updated_conversation},\n",
    "    {\"existing\": existing_memories},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_248ae003d44c4e3dbda77b8f'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_248ae003d44c4e3dbda77b8f)\n",
      " Call ID: call_248ae003d44c4e3dbda77b8f\n",
      "  Args:\n",
      "    content: User is planning to return to Japan this winter.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User is planning to return to Japan this winter.'\n"
     ]
    }
   ],
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'Memory',\n",
       "   'args': {'content': 'User is planning to return to Japan this winter.'},\n",
       "   'id': 'call_248ae003d44c4e3dbda77b8f',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the tool calls made by Trustcall\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Memory created:\n",
      "Content: {'content': 'User is planning to return to Japan this winter.'}\n"
     ]
    }
   ],
   "source": [
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"Extract information from tool calls for both patches and new memories.\n",
    "\n",
    "    Args:\n",
    "        tool_calls: List of tool calls from the model\n",
    "        schema_name: Name of the schema tool (e.g., \"Memory\", \"ToDo\", \"Profile\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list of changes\n",
    "    changes = []\n",
    "\n",
    "    for call_group in tool_calls:\n",
    "        for call in call_group:\n",
    "            if call[\"name\"] == \"PatchDoc\":\n",
    "                changes.append(\n",
    "                    {\n",
    "                        \"type\": \"update\",\n",
    "                        \"doc_id\": call[\"args\"][\"json_doc_id\"],\n",
    "                        \"planned_edits\": call[\"args\"][\"planned_edits\"],\n",
    "                        \"value\": call[\"args\"][\"patches\"][0][\"value\"],\n",
    "                    }\n",
    "                )\n",
    "            elif call[\"name\"] == schema_name:\n",
    "                changes.append({\"type\": \"new\", \"value\": call[\"args\"]})\n",
    "\n",
    "    # Format results as a single string\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change[\"type\"] == \"update\":\n",
    "            result_parts.append(\n",
    "                f\"Document {change['doc_id']} updated:\\n\"\n",
    "                f\"Plan: {change['planned_edits']}\\n\"\n",
    "                f\"Added content: {change['value']}\"\n",
    "            )\n",
    "        else:\n",
    "            result_parts.append(\n",
    "                f\"New {schema_name} created:\\n\" f\"Content: {change['value']}\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\\n\".join(result_parts)\n",
    "\n",
    "\n",
    "# Inspect spy.called_tools to see exactly what happened during the extraction\n",
    "schema_name = \"Memory\"\n",
    "changes = extract_tool_info(spy.called_tools, schema_name)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建智能体\n",
    "\n",
    "有许多不同的[智能体](https://langchain-ai.github.io/langgraph/concepts/high_level/)架构可选。\n",
    "\n",
    "这里我们实现一个简单的 [ReAct](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation) 智能体。\n",
    "\n",
    "它将成为创建与管理 ToDo 清单的贴心助手。\n",
    "\n",
    "这个智能体会根据需要更新三类长期记忆：\n",
    "\n",
    "(a) 创建或更新包含通用用户信息的 `profile`\n",
    "\n",
    "(b) 在 ToDo `collection` 中新增或修改条目\n",
    "\n",
    "(c) 更新自身用于创建 ToDo 项的 `instructions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "\n",
    "# Update memory tool\n",
    "# 三种更新情况：user, todo, instructions\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\"Decision on what memory type to update\"\"\"\n",
    "\n",
    "    update_type: Literal[\"user\", \"todo\", \"instructions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图定义\n",
    "\n",
    "我们添加一个简单的路由器 `route_message`，用于二选一地决定是否保存记忆。\n",
    "\n",
    "集合的更新依旧由 `write_memory` 节点里的 Trustcall 负责。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = ChatTongyi(model=\"qwen3-max\", temperature=0)\n",
    "\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
    "\n",
    "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
    "    location: Optional[str] = Field(description=\"The user's location\", default=None)\n",
    "    job: Optional[str] = Field(description=\"The user's job\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"Personal connection of the user, such as family members, friends, or coworkers\",\n",
    "        default_factory=list,\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"Interests that the user has\", default_factory=list\n",
    "    )\n",
    "\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"The task to be completed.\")\n",
    "    time_to_complete: Optional[int] = Field(\n",
    "        description=\"Estimated time to complete the task (minutes).\"\n",
    "    )\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"When the task needs to be completed by (if applicable)\",\n",
    "        default=None,\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"List of specific, actionable solutions (e.g., specific ideas, service providers, or concrete options relevant to completing the task)\",\n",
    "        min_items=1,\n",
    "        default_factory=list,\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"Current status of the task\", default=\"not started\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profile\n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    # tool_choice=\"Profile\",\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "You are designed to be a companion to a user, helping them keep track of their ToDo list.\n",
    "\n",
    "You have a long term memory which keeps track of three things:\n",
    "1. The user's profile (general information about them) \n",
    "2. The user's ToDo list\n",
    "3. General instructions for updating the ToDo list\n",
    "\n",
    "Here is the current User Profile (may be empty if no information has been collected yet):\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Here is the current ToDo List (may be empty if no tasks have been added yet):\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "Here are the current user-specified preferences for updating the ToDo list (may be empty if no preferences have been specified yet):\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "Here are your instructions for reasoning about the user's messages:\n",
    "\n",
    "1. Reason carefully about the user's messages as presented below. \n",
    "\n",
    "2. Decide whether any of the your long-term memory should be updated:\n",
    "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
    "- If tasks are mentioned, update the ToDo list by calling UpdateMemory tool with type `todo`\n",
    "- If the user has specified preferences for how to update the ToDo list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
    "\n",
    "3. Tell the user that you have updated your memory, if appropriate:\n",
    "- Do not tell the user you have updated the user's profile\n",
    "- Tell the user them when you update the todo list\n",
    "- Do not tell the user that you have updated instructions\n",
    "\n",
    "4. Err on the side of updating the todo list. No need to ask for explicit permission.\n",
    "\n",
    "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously.\n",
    "\n",
    "System Time: {time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
    "\n",
    "Based on this interaction, update your instructions for how to update ToDo list items. \n",
    "\n",
    "Use any feedback from the user to update how they like to have items added, etc.\n",
    "\n",
    "Your current instructions are:\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "\n",
    "# Node definitions\n",
    "def task_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 检索三种memory： user profile, todo list, instructions\n",
    "    # Retrieve profile memory from the store\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # Retrieve task memory from the store\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # Retrieve custom instructions\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(\n",
    "        user_profile=user_profile, todo=todo, instructions=instructions\n",
    "    )\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    # 决定是否调用UpdateMemory工具以及调用哪一个（profile/todo/instruction）\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke(\n",
    "        [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Profile\"\n",
    "    existing_memories = (\n",
    "        [\n",
    "            (existing_item.key, tool_name, existing_item.value)\n",
    "            for existing_item in existing_items\n",
    "        ]\n",
    "        if existing_items\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(\n",
    "        time=datetime.now().isoformat()\n",
    "    )\n",
    "    updated_messages = list(\n",
    "        merge_message_runs(\n",
    "            messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)]\n",
    "            + state[\"messages\"][:-1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke(\n",
    "        # {\"messages\": updated_messages, \"existing\": existing_memories}\n",
    "        {\"messages\": updated_messages},\n",
    "        {\"existing\": existing_memories},\n",
    "    )\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(\n",
    "            namespace,\n",
    "            rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "            r.model_dump(mode=\"json\"),\n",
    "        )\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "\n",
    "    ##################### important #####################\n",
    "    # 向agent返回工具消息，表示原始工具调用已完成\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"updated profile\",\n",
    "                \"tool_call_id\": tool_calls[0][\"id\"],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"ToDo\"\n",
    "    existing_memories = (\n",
    "        [\n",
    "            (existing_item.key, tool_name, existing_item.value)\n",
    "            for existing_item in existing_items\n",
    "        ]\n",
    "        if existing_items\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(\n",
    "        time=datetime.now().isoformat()\n",
    "    )\n",
    "    updated_messages = list(\n",
    "        merge_message_runs(\n",
    "            messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)]\n",
    "            + state[\"messages\"][:-1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ############### diffrent from `update_profile` ###############\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
    "    spy = Spy()\n",
    "\n",
    "    # Create the Trustcall extractor for updating the ToDo list\n",
    "    todo_extractor = create_extractor(\n",
    "        model,\n",
    "        tools=[ToDo],\n",
    "        # tool_choice=tool_name,\n",
    "        tool_choice=\"auto\",\n",
    "        enable_inserts=True,\n",
    "    ).with_listeners(on_end=spy)\n",
    "    ##############################################################\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke(\n",
    "        # {\"messages\": updated_messages, \"existing\": existing_memories}\n",
    "        {\"messages\": updated_messages},\n",
    "        {\"existing\": existing_memories},\n",
    "    )\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(\n",
    "            namespace,\n",
    "            rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "            r.model_dump(mode=\"json\"),\n",
    "        )\n",
    "\n",
    "    # Respond to the tool call made in task_mAIstro, confirming the update\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_mAIstro\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": todo_update_msg,\n",
    "                \"tool_call_id\": tool_calls[0][\"id\"],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(\n",
    "        current_instructions=existing_memory.value if existing_memory else None\n",
    "    )\n",
    "\n",
    "    ####################### diffrent from `update_profile` #######################\n",
    "    ####################### diffrent from `update_todo` #######################\n",
    "    new_memory = model.invoke(\n",
    "        [SystemMessage(content=system_msg)]\n",
    "        + state[\"messages\"][:-1]\n",
    "        + [\n",
    "            HumanMessage(\n",
    "                content=\"Please update the instructions based on the conversation\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Overwrite the existing memory in the store\n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    ######################################################\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"updated instructions\",\n",
    "                \"tool_call_id\": tool_calls[0][\"id\"],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(\n",
    "    state: MessagesState, config: RunnableConfig, store: BaseStore\n",
    ") -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    \"\"\"\n",
    "    1. 检查是否有tool call\n",
    "    2. 如果有，根据update_type决定调用哪个更新函数\n",
    "    3. 如果没有，返回END\n",
    "    \"\"\"\n",
    "    message = state[\"messages\"][-1]\n",
    "    if len(message.tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call[\"args\"][\"update_type\"] == \"user\":\n",
    "            return \"update_profile\"\n",
    "        elif tool_call[\"args\"][\"update_type\"] == \"todo\":\n",
    "            return \"update_todos\"\n",
    "        elif tool_call[\"args\"][\"update_type\"] == \"instructions\":\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Lance. I live in SF with my wife. I have a 1 year old daughter.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_afb8ecfc47de4ee0828b379f)\n",
      " Call ID: call_afb8ecfc47de4ee0828b379f\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! It sounds like you have a wonderful family. Let me know if there's anything specific you'd like to keep track of or if you need help with anything!\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Lance\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"My name is Lance. I live in SF with my wife. I have a 1 year old daughter.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My wife asked me to book swim lessons for the baby.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_dcc53b0c49984558a200503b)\n",
      " Call ID: call_dcc53b0c49984558a200503b\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Book swim lessons for 1-year-old daughter', 'time_to_complete': '30', 'deadline': '2025-10-13T22:33:57.369364', 'status': 'not started', 'solutions': ['Search for local swim schools in San Francisco that offer infant/toddler swim classes (e.g., Aqua-Tots, Goldfish Swim School, or YMCA)', 'Check class availability and schedules', 'Read reviews or ask for recommendations from local parenting groups', 'Contact the selected swim school to enroll your daughter']}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Book swim lessons for 1-year-old daughter\" to your ToDo list! The task includes some helpful steps like searching for local swim schools in San Francisco, checking availability, reading reviews, and enrolling your daughter. Let me know if you'd like to adjust anything or need help with the next steps!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [\n",
    "    HumanMessage(content=\"My wife asked me to book swim lessons for the baby.\")\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating ToDo items, include specific local businesses / vendors.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_6b898203e8b44873be51628e)\n",
      " Call ID: call_6b898203e8b44873be51628e\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! I'll make sure to include specific local businesses and vendors in San Francisco when creating or updating your ToDo items. Let me know if there's anything else you'd like me to keep in mind!\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"When creating or updating ToDo items, include specific local businesses / vendors.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': '<current_instructions>\\nWhen creating or updating ToDo list items, include specific local businesses or vendors relevant to the task, especially those in San Francisco. For example, when booking swim lessons for a baby, suggest actual local options such as Aqua-Tots, Goldfish Swim School, or the YMCA in SF. Always aim to provide actionable, location-specific recommendations to support task completion.\\n</current_instructions>'}\n"
     ]
    }
   ],
   "source": [
    "# Check for updated instructions\n",
    "user_id = \"Lance\"\n",
    "\n",
    "# Search\n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need to fix the jammed electric Yale lock on the door.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_272d55908463432395f73904)\n",
      " Call ID: call_272d55908463432395f73904\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Fix the jammed electric Yale lock on the door', 'time_to_complete': '45', 'deadline': '2025-10-06T22:34:18.567208', 'status': 'not started', 'solutions': ['Contact Yale Lock Support (1-800-628-5325) for troubleshooting guidance specific to your model', 'Schedule a service appointment with a local San Francisco locksmith experienced with smart locks (e.g., San Francisco Locksmith Service, Bay Area Locksmith, or Pop-A-Lock SF)', 'Check if the issue is battery-related by replacing batteries with fresh ones', 'Consult the Yale lock manual or app for reset or recalibration instructions']}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Fix the jammed electric Yale lock on the door\" to your ToDo list! The task includes actionable steps like contacting Yale Lock Support, scheduling a service appointment with a local San Francisco locksmith (such as San Francisco Locksmith Service, Bay Area Locksmith, or Pop-A-Lock SF), checking the batteries, and consulting the manual or app for troubleshooting. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [\n",
    "    HumanMessage(content=\"I need to fix the jammed electric Yale lock on the door.\")\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Book swim lessons for 1-year-old daughter', 'time_to_complete': 30, 'deadline': '2025-10-13T22:33:57.369364', 'solutions': ['Search for local swim schools in San Francisco that offer infant/toddler swim classes (e.g., Aqua-Tots, Goldfish Swim School, or YMCA)', 'Check class availability and schedules', 'Read reviews or ask for recommendations from local parenting groups', 'Contact the selected swim school to enroll your daughter'], 'status': 'not started'}\n",
      "{'task': 'Fix the jammed electric Yale lock on the door', 'time_to_complete': 45, 'deadline': '2025-10-06T22:34:18.567208', 'solutions': ['Contact Yale Lock Support (1-800-628-5325) for troubleshooting guidance specific to your model', 'Schedule a service appointment with a local San Francisco locksmith experienced with smart locks (e.g., San Francisco Locksmith Service, Bay Area Locksmith, or Pop-A-Lock SF)', 'Check if the issue is battery-related by replacing batteries with fresh ones', 'Consult the Yale lock manual or app for reset or recalibration instructions'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Lance\"\n",
    "\n",
    "# Search\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the swim lessons, I need to get that done by end of November.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_43ef9394b5e04c84837be3bc)\n",
      " Call ID: call_43ef9394b5e04c84837be3bc\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Book swim lessons for 1-year-old daughter', 'time_to_complete': '30', 'deadline': '2025-11-30T23:59:59', 'status': 'not started', 'solutions': ['Search for local swim schools in San Francisco that offer infant/toddler swim classes (e.g., Aqua-Tots San Francisco, Goldfish Swim School – San Francisco, or YMCA locations like Chinatown YMCA or Mission Bay YMCA)', 'Check class availability and schedules for sessions starting before end of November', 'Read reviews or ask for recommendations from local parenting groups like SF Parents or Nextdoor', 'Contact the selected swim school to enroll your daughter']}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated your swim lessons task with a deadline of November 30th and included specific San Francisco swim schools like Aqua-Tots San Francisco, Goldfish Swim School – San Francisco, and YMCA locations (Chinatown YMCA or Mission Bay YMCA). The task also suggests checking availability for sessions starting before the end of November and getting recommendations from local parenting groups like SF Parents or Nextdoor. Let me know if you'd like any adjustments!\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"For the swim lessons, I need to get that done by end of November.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 Trustcall 对已有记忆执行了补丁更新：\n",
    "\n",
    "https://smith.langchain.com/public/4ad3a8af-3b1e-493d-b163-3111aa3d575a/r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Need to call back City Toyota to schedule car service.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_64b069cee49345238254a58d)\n",
      " Call ID: call_64b069cee49345238254a58d\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Call back City Toyota to schedule car service', 'time_to_complete': '15', 'deadline': '2025-10-06T22:34:49.562801', 'status': 'not started', 'solutions': ['Call City Toyota Service Department directly at (415) 555-1234 (main number—confirm exact line for service scheduling)', 'Use the Toyota Owners portal or app to schedule service online if preferred', 'Have your VIN and preferred service date ready when calling', 'Ask about wait times and whether they offer loaner vehicles or shuttle service']}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Call back City Toyota to schedule car service\" to your ToDo list! The task includes helpful steps like calling their service department, using the Toyota Owners portal or app, having your VIN ready, and asking about loaner vehicles or shuttle service. Let me know if you need any modifications or additional details!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [\n",
    "    HumanMessage(content=\"Need to call back City Toyota to schedule car service.\")\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Book swim lessons for 1-year-old daughter', 'time_to_complete': 30, 'deadline': '2025-10-13T22:33:57.369364', 'solutions': ['Search for local swim schools in San Francisco that offer infant/toddler swim classes (e.g., Aqua-Tots, Goldfish Swim School, or YMCA)', 'Check class availability and schedules', 'Read reviews or ask for recommendations from local parenting groups', 'Contact the selected swim school to enroll your daughter'], 'status': 'not started'}\n",
      "{'task': 'Fix the jammed electric Yale lock on the door', 'time_to_complete': 45, 'deadline': '2025-10-06T22:34:18.567208', 'solutions': ['Contact Yale Lock Support (1-800-628-5325) for troubleshooting guidance specific to your model', 'Schedule a service appointment with a local San Francisco locksmith experienced with smart locks (e.g., San Francisco Locksmith Service, Bay Area Locksmith, or Pop-A-Lock SF)', 'Check if the issue is battery-related by replacing batteries with fresh ones', 'Consult the Yale lock manual or app for reset or recalibration instructions'], 'status': 'not started'}\n",
      "{'task': 'Book swim lessons for 1-year-old daughter', 'time_to_complete': 30, 'deadline': '2025-11-30T23:59:59', 'solutions': ['Search for local swim schools in San Francisco that offer infant/toddler swim classes (e.g., Aqua-Tots San Francisco, Goldfish Swim School – San Francisco, or YMCA locations like Chinatown YMCA or Mission Bay YMCA)', 'Check class availability and schedules for sessions starting before end of November', 'Read reviews or ask for recommendations from local parenting groups like SF Parents or Nextdoor', 'Contact the selected swim school to enroll your daughter'], 'status': 'not started'}\n",
      "{'task': 'Call back City Toyota to schedule car service', 'time_to_complete': 15, 'deadline': '2025-10-06T22:34:49.562801', 'solutions': ['Call City Toyota Service Department directly at (415) 555-1234 (main number—confirm exact line for service scheduling)', 'Use the Toyota Owners portal or app to schedule service online if preferred', 'Have your VIN and preferred service date ready when calling', 'Ask about wait times and whether they offer loaner vehicles or shuttle service'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Lance\"\n",
    "\n",
    "# Search\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以创建一个新线程。\n",
    "\n",
    "这就相当于开启一个全新会话。\n",
    "\n",
    "长期记忆中保存的档案、ToDo 与指令都会被读取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have 30 minutes, what tasks can I get done?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on your current ToDo list and the 30 minutes you have available, here are the tasks you can realistically complete:\n",
      "\n",
      "1. **Call back City Toyota to schedule car service**  \n",
      "   - Estimated time: 15 minutes  \n",
      "   - This is well within your available time.  \n",
      "   - Solutions: Call City Toyota Service Department at (415) 555-1234, use the Toyota Owners portal/app, have your VIN ready, and ask about wait times or loaner vehicles.\n",
      "\n",
      "2. **Book swim lessons for your 1-year-old daughter**  \n",
      "   - Estimated time: 30 minutes  \n",
      "   - This fits exactly within your available window.  \n",
      "   - Solutions: Search for local swim schools like Aqua-Tots San Francisco, Goldfish Swim School – San Francisco, or YMCA locations (Chinatown or Mission Bay), check availability, read reviews from SF Parents or Nextdoor, and contact your chosen school to enroll.\n",
      "\n",
      "Would you like to tackle one of these now?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"Lance\"}}\n",
    "\n",
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"I have 30 minutes, what tasks can I get done?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yes, give me some options to call for swim lessons.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some great San Francisco swim schools that offer infant/toddler swim classes for your 1-year-old daughter:\n",
      "\n",
      "1. **Aqua-Tots San Francisco**  \n",
      "   - Website: [aquatots.com/locations/ca/san-francisco](https://www.aquatots.com/locations/ca/san-francisco)  \n",
      "   - Phone: (415) 555-2345  \n",
      "   - Offers classes specifically for babies as young as 6 months  \n",
      "\n",
      "2. **Goldfish Swim School – San Francisco (Marina District)**  \n",
      "   - Website: [goldfishswimschool.com/sanfrancisco](https://www.goldfishswimschool.com/sanfrancisco)  \n",
      "   - Phone: (415) 555-3456  \n",
      "   - Warm water pools and curriculum designed for young children  \n",
      "\n",
      "3. **YMCA of San Francisco – Chinatown or Mission Bay Locations**  \n",
      "   - Chinatown YMCA: (415) 555-4567  \n",
      "   - Mission Bay YMCA: (415) 555-5678  \n",
      "   - Website: [ymcasf.org](https://www.ymcasf.org)  \n",
      "   - Offers parent-child swim classes and is often more affordable  \n",
      "\n",
      "4. **Little Otter Swim School (Potrero Hill)**  \n",
      "   - Website: [littleotterswim.com](https://www.littleotterswim.com)  \n",
      "   - Phone: (415) 555-6789  \n",
      "   - Specializes in early childhood aquatics with small class sizes  \n",
      "\n",
      "Would you like help calling one of these, or do you want to check availability online first?\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [\n",
    "    HumanMessage(content=\"Yes, give me some options to call for swim lessons.\")\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追踪：\n",
    "\n",
    "https://smith.langchain.com/public/84768705-be91-43e4-8a6f-f9d3cee93782/r\n",
    "\n",
    "## Studio\n",
    "\n",
    "![Screenshot 2024-11-04 at 1.00.19 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732cfb05d9709862eba4e6c_Screenshot%202024-11-11%20at%207.46.40%E2%80%AFPM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疑问\n",
    "\n",
    "为什么不是由大模型直接选择执行的tool（update_todo/update_profile/update_instructions），而是需要中间夹一层update memory显式判断???\n",
    "\n",
    "应该修改task_mAIstro函数？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
